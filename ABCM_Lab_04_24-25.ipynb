{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "662e7749",
   "metadata": {},
   "source": [
    "# ABCM Computer lab 4: Variation & Convergence in Populations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a1aab4",
   "metadata": {},
   "source": [
    "In this computer lab, we will explore the agent-based model described in Mudd, K., de Vos, C., & de Boer, B. (2022). Shared Context Facilitates Lexical Variation in Sign Language Emergence. Languages, 7(1), Article 1. [https://doi.org/10.3390/languages7010031](https://doi.org/10.3390/languages7010031)\n",
    "\n",
    "Below, we use the Python code written by the first author Katie Mudd herself, which she shared openly on Figshare: [https://doi.org/10.6084/m9.figshare.15163872.v1](https://doi.org/10.6084/m9.figshare.15163872.v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b48766",
   "metadata": {},
   "source": [
    "This code makes use of the [Mesa](https://mesa.readthedocs.io/en/latest/) package, which is a Python framework for agent-based modelling. It allows users to quickly create agent-based models using built-in core components (such as spatial grids and agent schedulers) or customized implementations. The code below uses four classes from the Mesa package:\n",
    "\n",
    "- ```Agent```\n",
    "- ```Model```\n",
    "- ```RandomActivation```\n",
    "- ```DataCollector```\n",
    "\n",
    "The generic ```Agent``` and ```Model``` class from the Mesa package are built upon in the code below (using [class inheritance](https://www.w3schools.com/python/python_inheritance.asp)) to create the specific type of agent needed for this model (called ```ContextAgent``` below), and the specific type of model needed (called ```ContextModel``` below). Using such a child class of the parent class ```Model```, the code can then use the built-in ```RandomActivation``` and ```DataCollector``` classes from the Mesa package to schedule the agents' interactions and keep track of various measures of the population's interactions and vocabularies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7118ad82",
   "metadata": {},
   "source": [
    "If you've created a virtual environment for this course before, **don't forgot to activate your virtual environment** before running this notebook. (Activate your virtual environment from the terminal, then type ```jupyter notebook``` in the terminal to open Jupyter notebooks in the browser, then open the notebook for this computer lab, and do Kernel --> Change kernel --> ```<myenv>```, where ```<myenv>``` is the name of your virtual environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e25d393",
   "metadata": {},
   "source": [
    "Let's first install the Mesa package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eb162a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:49:42.743767Z",
     "start_time": "2024-08-30T09:49:36.140376Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install mesa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6f8664",
   "metadata": {},
   "source": [
    "Then, let's import all the packages, classes and functions we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42da3d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:49:48.060815Z",
     "start_time": "2024-08-30T09:49:45.237194Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "from math import sqrt\n",
    "import time\n",
    "from mesa import Agent, Model\n",
    "from mesa.datacollection import DataCollector\n",
    "from mesa.time import RandomActivation\n",
    "from mesa.batchrunner import BatchRunner, FixedBatchRunner\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a7e16",
   "metadata": {},
   "source": [
    "## Parameter settings:\n",
    "\n",
    "The code cell below contains the parameter settings that we'll need to run simulations further down in the notebook. Below, these parameters are combined in a dictionary, which is the datastructure that the code below expects when retrieving these parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbd229a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:49:49.727515Z",
     "start_time": "2024-08-30T09:49:49.719767Z"
    }
   },
   "outputs": [],
   "source": [
    "################# PARAMETER SETTINGS: ################# \n",
    "\n",
    "test_params = dict(\n",
    "    n_concepts=10, # int: number of concepts\n",
    "    n_bits=10,  # int: number of bits (determining length of forms and culturally-salient feature vectors)\n",
    "    n_agents=10, # int: number of agents in the population\n",
    "    n_groups=1,  # determines how many different semantic groups there are\n",
    "    initial_degree_of_overlap=0.9,  # degree of overlap between the form and meaning components\n",
    "    n_steps=2000  # number of timesteps to run the simulation for (called \"model stages\" in the paper)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea32b0fa",
   "metadata": {},
   "source": [
    "## Initialising the population and their language representations\n",
    "\n",
    "As described on page 7 of Mudd et al. (2022) (see **Initialization** paragraph), each agent in the population has a language representation that consists of ```n_concepts``` concepts, where each concept is associated with (i) a set of culturally salient features, and (ii) a form. The set of culturally salient features and the form both consist of ```n_bits``` bits. (Also see Figure 4 in the paper.)\n",
    "\n",
    "The vector of culturally salient features represents the _meaning_ of the concept to the agent (which depends on their cultural background; i.e., the group they belong to). The form vector represents the _form_ (i.e., signal) that the agent would use in order to convey that concept.\n",
    "The parameter ```initial_degree_of_overlap``` determines the degree of overlap between the culturally salient features vector and the form. If this degree of overlap is high, that simulates a form that is highly _iconic_ (i.e., when aspects of the form resemble aspects of the meaning).\n",
    "\n",
    "The code in this section takes care of initialising the population and each agent's language representations, depending on which group in the population they belong to.\n",
    "\n",
    "This is done using the following four functions:\n",
    "- ```language_skeleton()```: Creates an empty language representation for an agent (where the meaning and form components are initialised with the value ```None```)\n",
    "- ```language_create_meanings()```: Randomly generates a bit vector of culturally-salient features for each concept, for each group in the population\n",
    "- ```language_add_meaning()```: Takes a particular agent object, and fills in the meaning vectors in its empty language representation with the bit vectors of culturally-salient features that correspond to the group that the agent belongs to\n",
    "- ```language_add_form()```: Takes a particular agent object, and fills in the form vectors in its empty language representation, depending on the setting of the ```initial_degree_of_overlap``` parameter, which determines the probability that a given bit of a meaning and form representation are the same (i.e., have the same value at the same index). (See top of page 9 in Mudd et al., 2022.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d4a4ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:49:51.279607Z",
     "start_time": "2024-08-30T09:49:51.271535Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_skeleton(n_concepts, n_bits):\n",
    "    \"\"\" initiate language with n_concepts and n_bits\n",
    "    in the form {0: [meaning, form], 1: [meaning, from], ...}\n",
    "    the meaning and form components are initiated with None \"\"\"\n",
    "    skeleton_concept_meaning_form = {}\n",
    "    for n in range(n_concepts):\n",
    "        skeleton_concept_meaning_form[n] = [[None] * n_bits] * 2\n",
    "    return skeleton_concept_meaning_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fee6141",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:49:51.913818Z",
     "start_time": "2024-08-30T09:49:51.900737Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_create_meanings(n_concepts, n_bits, n_groups):\n",
    "    \"\"\" generate the meaning representation for each group\n",
    "    returns a dictionary with group: meaning representation\n",
    "    ex. {0: [[1, 1, 0, 1, 1], [0, 0, 0, 1, 0]], 1: [[0, 0, 0, 1, 1], [1, 1, 1, 1, 0]]} \"\"\"\n",
    "    group_meaning_dic = {}\n",
    "    for n in range(n_groups):\n",
    "        condition = False\n",
    "        while condition == False:\n",
    "            single_group_meaning_list = []\n",
    "            for concept in range(n_concepts):\n",
    "                single_group_meaning_list.append(random.choices([0, 1], k=n_bits))  # list of len n_components\n",
    "            if len(set(tuple(row) for row in single_group_meaning_list)) == len(\n",
    "                    single_group_meaning_list):\n",
    "                condition = True\n",
    "                group_meaning_dic[n] = single_group_meaning_list\n",
    "                \n",
    "    return group_meaning_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c434b9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:49:52.441123Z",
     "start_time": "2024-08-30T09:49:52.431158Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_add_meaning(agent, meaning_dic):\n",
    "    \"\"\" takes in the language skeleton and adds the meaning component depending on group of agent \"\"\"\n",
    "    counter = 0  # to keep track of which meaning component in meaning_dic values\n",
    "    for concept, meaning_form in agent.language_rep.items():\n",
    "        meaning_form[0] = meaning_dic[agent.group][counter]  # meaning_form[0] is the meaning only\n",
    "        counter += 1\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf725526",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:49:53.082827Z",
     "start_time": "2024-08-30T09:49:53.068356Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_add_form(agent, initial_degree_of_overlap):\n",
    "    \"\"\" start with meaning representation and assign form representation\n",
    "    depending on the desired degree of overlap \"\"\"\n",
    "    for concept, meaning_form in agent.language_rep.items():\n",
    "        forms = []\n",
    "        for bit in meaning_form[0]:\n",
    "            my_choice = np.random.choice([True, False], p=[initial_degree_of_overlap, 1 - initial_degree_of_overlap])  # p = weights\n",
    "            if not my_choice:  # if my_choice == False\n",
    "                random_choice = np.random.choice([0, 1])\n",
    "                forms.append(random_choice)  # random choice 0 or 1 if False (random)\n",
    "            else:\n",
    "                forms.append(bit)  # append the same bit (iconic)\n",
    "        meaning_form[1] = forms\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7ab483",
   "metadata": {},
   "source": [
    "## Running a language game and updating the agents' language representations\n",
    "\n",
    "As described in pages 9-10 and Figure 5 of Mudd et al. (2022), there are four different stages that a sender-receiver pair can go through in a language game interaction:\n",
    "\n",
    "1. _signal production_: First, the sender randomly chooses a concept and produces the corresponding form given by the sender's language representation (this form is the signal that the sender produces).\n",
    "\n",
    "2. _form success_: The receiver finds the form which is closest to the sender's form in the receiver's language representation (by calculating the distance between the sender's form to all forms of the receiver, and choosing the form with the smallest distance). If the concept for that form in the receiver's language representation is the same as the concept that the sender wanted to convey, the pair has achieved _form success_ (by using the _conventional link_ between a concept and a form). If the pair has achieved _form success_, the language game ends here.\n",
    "\n",
    "3. _culturally salient features success_: If the pair has _not_ achieved _form success_, the receiver now tries to make use of the _iconic–inferential pathway_ (where a form and concept are linked via the culturally salient features) in order to interpret the sender's signal (see Figure 2 in Mudd et al., 2022). The receiver does this by comparing the sender's form to all sets of culturally salient features in the receiver's language representation (again by calculating the distance and choosing the concept that has the smallest distance to the sender's form). If the concept chosen in this way is the same as the concept that the sender wanted to convey, the pair has achieved _culturally salient features success_, and the game ends here.\n",
    "\n",
    "4. _bit update_: If the pair has achieved neither _form success_ nor _culturally salient features success_, the receiver proceeds by updating the form that they associate with the concept that the sender wanted to convey. The receiver does this by updating one bit of their form which is different from the form of the sender.\n",
    "\n",
    "The five functions below take care of the following:\n",
    "\n",
    "- ```language_game()```: Iterates over all agents in the population (sorted by group), assigns them the role of sender, and has them play a language game with a randomly selected other agent from the population. Returns a dictionary that keeps track of how many times the agent pairs in the population reached (i) _form success_, (ii) _culturally salient features success_, or (iii) did a _bit update_\n",
    "\n",
    "- ```language_game_structure()```: Takes a given producer agent and has them play a language game with a randomly selected other agent from the population\n",
    "\n",
    "- ```does_closest_form_match()```: **Corresponds to Step 2 above:** Checks whether the closest form in the receiver's language representation matches the concept that the sender wanted to convey (if so, the agent pair achieves _form success_; see ```language_game_structure()```).\n",
    "\n",
    "- ```does_closest_meaning_match()```: **Corresponds to Step 3 above:** Checks whether the meaning vector that most closely matches the sender's form in the receiver's language representation matches the concept that the sender wanted to convey (if so, the agent pair achieves _culturally salient features success_; see ```language_game_structure()```).\n",
    "\n",
    "- ```update_comprehender_concept()```: **Corresponds to Step 4 above:** This function is used when the agent pair has achieved neither _form success_ nor _culturally salient features success_ (see ```language_game_structure()```). It takes the form that the receiver associates with the concept that the sender wanted to convey, and changes one bit in that form to make it more similar to the form that the sender associates with that concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4223046",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:49:54.401747Z",
     "start_time": "2024-08-30T09:49:54.391471Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_game(sorted_agent_list):\n",
    "    \"\"\" takes agent list sorted by group\n",
    "    chooses and agent to be the producer \"\"\"\n",
    "    form_success = 0\n",
    "    meaning_success = 0\n",
    "    bit_update = 0\n",
    "\n",
    "    for a in sorted_agent_list:\n",
    "        what_is_updated = language_game_structure(a, sorted_agent_list)\n",
    "\n",
    "        if what_is_updated == \"3a\":\n",
    "            form_success += 1\n",
    "        elif what_is_updated == \"3b1\":\n",
    "            meaning_success += 1\n",
    "        else:  # \"3b2\"\n",
    "            bit_update += 1\n",
    "\n",
    "    language_game_stats = {\"form_success\": form_success, \"meaning_success\": meaning_success, \"bit_update\": bit_update}\n",
    "    return language_game_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded6c997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:49:54.927973Z",
     "start_time": "2024-08-30T09:49:54.916437Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_game_structure(producer, all_agents):\n",
    "    comprehender = random.choice(all_agents)\n",
    "    producer_concept_choice = random.choice(list(producer.language_rep))  # 1\n",
    "    form_match_answer = does_closest_form_match(producer, producer_concept_choice, comprehender)  # 2\n",
    "    if form_match_answer == False:  # 3b\n",
    "        meaning_match_answer = does_closest_meaning_match(producer, producer_concept_choice, comprehender)\n",
    "        if meaning_match_answer == False:  # 3b2\n",
    "            update_comprehender_concept(producer, producer_concept_choice, comprehender)\n",
    "            return \"3b2\"\n",
    "        else:  # 3b1\n",
    "            # None\n",
    "            return \"3b1\"\n",
    "    else:  # 3a\n",
    "        # None\n",
    "        return \"3a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f006c3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:49:55.556202Z",
     "start_time": "2024-08-30T09:49:55.541556Z"
    }
   },
   "outputs": [],
   "source": [
    "def does_closest_form_match(producer, producer_concept_choice, comprehender):\n",
    "    produced_form = producer.language_rep[producer_concept_choice][1]\n",
    "\n",
    "    distance_from_produced_form = {}\n",
    "    for concept, meaning_form in comprehender.language_rep.items():\n",
    "        # compare produced concept and all comp concepts, calculate distance between each\n",
    "        distance = sum([abs(prod_bit - comp_bit) for prod_bit, comp_bit in zip(produced_form, meaning_form[1])])\n",
    "        distance_from_produced_form[concept] = distance\n",
    "\n",
    "    min_distance = min(distance_from_produced_form.values())\n",
    "    comp_closest_form_list = [concept for concept, distance in distance_from_produced_form.items() if distance == min_distance]\n",
    "    comp_chosen_form = random.choice(comp_closest_form_list)  # because there can be multiple, randomly choose from list\n",
    "\n",
    "    return producer_concept_choice == comp_chosen_form  # returns True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba28320c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:49:56.088088Z",
     "start_time": "2024-08-30T09:49:56.076654Z"
    }
   },
   "outputs": [],
   "source": [
    "def does_closest_meaning_match(producer, producer_concept_choice, comprehender):\n",
    "    produced_form = producer.language_rep[producer_concept_choice][1]\n",
    "\n",
    "    distance_from_produced_form = {}\n",
    "    for concept, meaning_form in comprehender.language_rep.items():\n",
    "        # compare produced concept and all comp concepts, calculate distance between each\n",
    "        distance = sum([abs(prod_bit - comp_bit) for prod_bit, comp_bit in zip(produced_form, meaning_form[0])])\n",
    "        distance_from_produced_form[concept] = distance\n",
    "    comp_closest_meaning = min(distance_from_produced_form, key=distance_from_produced_form.get)\n",
    "\n",
    "    return comp_closest_meaning == producer_concept_choice  # returns True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea13b3b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:49:56.627142Z",
     "start_time": "2024-08-30T09:49:56.614502Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_comprehender_concept(producer, producer_concept_choice, comprehender):\n",
    "    \"\"\" update comprehender form\n",
    "    compare all producer and comprehender form, find the ones that don't match\n",
    "    of the ones that don't match, choose one and flip this bit of the comprehender's form \"\"\"\n",
    "    comparison_list = ([(p_bit == c_bit) for p_bit, c_bit in zip(producer.language_rep[producer_concept_choice][1], comprehender.language_rep[producer_concept_choice][1])])\n",
    "    # to prevent case where correct concept has a match for form producer and comprehender\n",
    "    # this could happen if comprehender has 2 forms which both == form producer and the non-matching concept one gets chosen\n",
    "    if all(comparison_list) == True:\n",
    "        pass\n",
    "    else:\n",
    "        correctable_indexes = [i for i, comparison in enumerate(comparison_list) if comparison == False]  # get False indeces\n",
    "        chosen_index_to_correct = random.choice(correctable_indexes)\n",
    "        comprehender.language_rep[producer_concept_choice][1][chosen_index_to_correct] = abs(1 - (comprehender.language_rep[producer_concept_choice][1][chosen_index_to_correct]))\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2830ba1c",
   "metadata": {},
   "source": [
    "**Exercise 1:**\n",
    "\n",
    "This is a conceptual question: How does the model of what happens in a communicative interaction that is used here differ from the models you've seen in Cuskley et al. (2018) and de Weerd et al. (2015) (i.e., the past two computer labs)? \n",
    "\n",
    "**a)** What determines whether a communicative interaction is successful or not, in these three different models? \n",
    "\n",
    "**b)** What happens in these three models if a communicative interaction is not immediately successful? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc1447f",
   "metadata": {},
   "source": [
    "**Answer to exercise 1.a):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20126d3a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f3d903a",
   "metadata": {},
   "source": [
    "**Answer to exercise 1.b):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cf5a85",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d17423d",
   "metadata": {},
   "source": [
    "**Exercise 2:** This is a conceptual question about the _bit update_ operation in Mudd et al. (2022) (see Step 4 above).\n",
    "\n",
    "**a)** In order for the _bit update_ operation to take place, the receiver needs to know what the sender's intended concept was. What process in real-life conversations between people could this map onto? How do we find out what concept someone means, if the word or sign they use for it is different from the one we'd use ourselves?\n",
    "\n",
    "**b)** What is it about the reception procedure (i.e. Steps 2 and 3 above) that makes it so that the _bit update_ procedure makes this particular sender-receiver pair more likely to reach communicative success the next time they communicate about this same concept, _even_ if the receiver's form is still not exactly the same as the sender's form for this concept after _bit update_ has taken place?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443522b1",
   "metadata": {},
   "source": [
    "**Answer to exercise 2.a):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dbd522",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ce10520",
   "metadata": {},
   "source": [
    "**Answer to exercise 2.b):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2dd5ec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "081d382c",
   "metadata": {},
   "source": [
    "## Data-collector functions\n",
    "\n",
    "The functions below are used to keep track of the degree of lexical variability and the degree of iconicity in the population (the measures that are plotted in Figures 9-11 in Mudd et al., 2022). See page 11 (section **Submodel Collect data**) of Mudd et al. (2022) for more details on how these measures are calculated exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b1834c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:50:00.567733Z",
     "start_time": "2024-08-30T09:50:00.558391Z"
    }
   },
   "outputs": [],
   "source": [
    "# lexical variability\n",
    "def calculate_pop_lex_var(agent_list, n_concepts):\n",
    "    pairs_of_agents = itertools.combinations(agent_list, r=2)\n",
    "\n",
    "    pairs_lex_var = []\n",
    "\n",
    "    for pair in pairs_of_agents:\n",
    "        pair_lex_var = calculate_distance(pair, n_concepts)\n",
    "        pairs_lex_var.append(pair_lex_var)\n",
    "\n",
    "    pop_av_lex_var = sum(pairs_lex_var) / len(list(itertools.combinations(agent_list, r=2)))\n",
    "    return (pop_av_lex_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5662807a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:50:01.095131Z",
     "start_time": "2024-08-30T09:50:01.085944Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_distance(pair, n_concepts):\n",
    "    \"\"\" per concept per agent pair, distance = 0 if concepts are the same, distance = 1 if concepts are different\n",
    "    add up concept distances and divide by total number of concepts \"\"\"\n",
    "    concept_lex_var_total = 0  # list of distances between individual concepts (compare iconic agent a and iconic agent b)\n",
    "    for n in range(n_concepts):\n",
    "        if pair[0].language_rep[n][1] != pair[1].language_rep[n][1]:\n",
    "            concept_lex_var_total += 1  # if concepts don't match, add 1 to distance\n",
    "\n",
    "    pair_mean_lex_var = concept_lex_var_total / n_concepts\n",
    "    return pair_mean_lex_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa5e6ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:50:01.834925Z",
     "start_time": "2024-08-30T09:50:01.825994Z"
    }
   },
   "outputs": [],
   "source": [
    "# iconicity\n",
    "def calculate_degree_of_iconicity(agent):\n",
    "    concept_iconicity_vals = []\n",
    "\n",
    "    for concept, meaning_form in agent.language_rep.items():\n",
    "        comparison_list = ([(p_bit == c_bit) for p_bit, c_bit in zip(meaning_form[0], meaning_form[1])])  # returns True or False for each comparison\n",
    "        concept_iconicity_val = sum(comparison_list) / len(comparison_list)\n",
    "        concept_iconicity_vals.append(concept_iconicity_val)\n",
    "\n",
    "    mean_agent_iconicity = sum(concept_iconicity_vals) / len(concept_iconicity_vals)\n",
    "    return mean_agent_iconicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175d18b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:50:02.420060Z",
     "start_time": "2024-08-30T09:50:02.412183Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_prop_iconicity(agent_list):\n",
    "    iconicity_list = [a.prop_iconicity for a in agent_list]\n",
    "    return sum(iconicity_list) / len(agent_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38642aec",
   "metadata": {},
   "source": [
    "## Defining the agent and the model as a whole (using the Mesa package)\n",
    "\n",
    "The two classes below inherit from the class Agent and Model from the Mesa package.\n",
    "\n",
    "- The ```ContextAgent``` class creates an agent, which is an object that consists of the following attributes:\n",
    "    - unique identifier\n",
    "    - a group it belongs to\n",
    "    - a language representation\n",
    "    - a degree of iconicity of its language representation\n",
    "\n",
    "- The ```ContextModel``` class creates a population of ```ContextAgent``` objects (arranged in groups) and has a method ```step()``` which steps through 1 timestep of a simulation. A single timestep consists of every agent in the population taking one turn at being a sender in a language game (paired up with a randomly chosen receiver). See also Figure 3 in Mudd et al. (2022).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313701ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:50:03.595300Z",
     "start_time": "2024-08-30T09:50:03.587539Z"
    }
   },
   "outputs": [],
   "source": [
    "class ContextAgent(Agent):\n",
    "    def __init__(self, unique_id, model, n_concepts, n_bits, n_groups):\n",
    "        super().__init__(unique_id, model)\n",
    "        self.group = random.choice(range(n_groups))\n",
    "        self.language_rep = language_skeleton(n_concepts, n_bits)  # dic = {concept: [[meaning], [form]}\n",
    "        self.prop_iconicity = None\n",
    "\n",
    "    def describe(self):\n",
    "        #print(f\"id = {self.unique_id}, prop iconicity = {self.prop_iconicity}, group = {self.group}, language = {self.language_rep}\")\n",
    "        print(self.language_rep)\n",
    "\n",
    "    def step(self):\n",
    "        self.prop_iconicity = calculate_degree_of_iconicity(self)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536e5ac0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:50:04.369868Z",
     "start_time": "2024-08-30T09:50:04.343735Z"
    }
   },
   "outputs": [],
   "source": [
    "class ContextModel(Model):\n",
    "    \"\"\"A model with some number of agents.\"\"\"\n",
    "    def __init__(self, n_agents, n_concepts, n_bits, n_groups, initial_degree_of_overlap, n_steps, viz_on=False):\n",
    "        super().__init__()\n",
    "        self.placement_counter = 0\n",
    "        self.n_agents = n_agents\n",
    "        self.n_groups = n_groups\n",
    "        self.n_concepts = n_concepts\n",
    "        self.n_bits = n_bits\n",
    "        self.n_steps = n_steps\n",
    "\n",
    "        self.current_step = 0\n",
    "        self.schedule = RandomActivation(self)\n",
    "        self.running = True  # for server\n",
    "        self.group_meanings_dic = language_create_meanings(n_concepts, n_bits, n_groups) # set up language structure (maybe eventually a class)\n",
    "\n",
    "        self.width_height = int(sqrt(n_agents))\n",
    "        self.coordinate_list = list(itertools.product(range(self.width_height), range(self.width_height)))  # generate coordinates for grid\n",
    "\n",
    "        # language game successes and failures\n",
    "        self.lg_form_success = 0\n",
    "        self.lg_meaning_success = 0\n",
    "        self.lg_bit_update = 0\n",
    "        self.language_game_stats = {'form_success': None, 'meaning_success': None, 'bit_update': None}\n",
    "\n",
    "        # for datacollector\n",
    "        self.pop_iconicity = None\n",
    "        self.pop_lex_var = None\n",
    "        self.datacollector = DataCollector({'pop_iconicity': 'pop_iconicity',\n",
    "                                            'pop_lex_var': 'pop_lex_var',\n",
    "                                            'current_step': 'current_step',\n",
    "                                            'lg_form_success': 'lg_form_success',\n",
    "                                            'lg_meaning_success': 'lg_meaning_success',\n",
    "                                            'lg_bit_update': 'lg_bit_update'},\n",
    "                                           {'group': lambda agent: agent.group,\n",
    "                                            'language': lambda agent: agent.language_rep,\n",
    "                                            'prop iconicity': lambda agent: agent.prop_iconicity})\n",
    "\n",
    "        # create agents\n",
    "        for i in range(self.n_agents):\n",
    "            a = ContextAgent(i, self, self.n_concepts, self.n_bits, self.n_groups)  # make a new agent\n",
    "            language_add_meaning(a, self.group_meanings_dic)  # add meaning to language skeleton\n",
    "            language_add_form(a, initial_degree_of_overlap)  # add form to language skeleton\n",
    "\n",
    "            self.schedule.add(a)  # add agent to list of agents\n",
    "            a.prop_iconicity = calculate_degree_of_iconicity(a)\n",
    "\n",
    "        self.sorted_agents = sorted(self.schedule.agents, key=lambda agent: agent.group)  # sort agents by group\n",
    "\n",
    "    def collect_data(self):\n",
    "        self.pop_iconicity = calculate_prop_iconicity(self.schedule.agents)\n",
    "        self.pop_lex_var = calculate_pop_lex_var(self.schedule.agents, self.n_concepts)\n",
    "        self.current_step = self.current_step\n",
    "        self.lg_form_success = self.language_game_stats['form_success']\n",
    "        self.lg_meaning_success = self.language_game_stats['meaning_success']\n",
    "        self.lg_bit_update = self.language_game_stats['bit_update']\n",
    "        self.datacollector.collect(self)\n",
    "\n",
    "    def tests(self, a):\n",
    "        assert len(self.group_meanings_dic) == self.n_groups\n",
    "        assert len(self.group_meanings_dic[0]) == self.n_concepts\n",
    "        assert len(self.group_meanings_dic[0][0]) == self.n_bits\n",
    "        assert len(a.language_rep) == self.n_concepts\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\" Advance the model by one step \"\"\"\n",
    "        self.collect_data()  # set up = year 0\n",
    "\n",
    "        if self.current_step == 0:\n",
    "            self.tests(random.choice(self.schedule.agents))  # run tests on a random agent\n",
    "\n",
    "        self.current_step += 1\n",
    "        self.language_game_stats = language_game(self.sorted_agents)  # language game (only after the set up = year 0)\n",
    "\n",
    "        #if self.current_step == self.n_steps:\n",
    "        #    upgma_df = pd.DataFrame()\n",
    "\n",
    "        #    for i in self.schedule.agents:\n",
    "        #        for key, value in i.language_rep.items():\n",
    "        #            new_row = {'id': i.unique_id, 'concept': key, 'form': value[1]}\n",
    "        #            upgma_df = upgma_df.append(new_row, ignore_index=True)\n",
    "\n",
    "        #    upgma_df.to_csv(\"upgma_data.csv\")\n",
    "\n",
    "        self.schedule.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b56652",
   "metadata": {},
   "source": [
    "## Running a single simulation\n",
    "\n",
    "Now that the ```ContextAgent``` and ```ContextModel``` classes have been defined, we can run a single simulation run. The number of timesteps for which a simulation runs is determined by the ```n_steps``` parameter (defined at the top of this notebook as one of the key-value pairs in the ```test_params``` dictionary).\n",
    "\n",
    "The code below shows how you can run a single simulation for a population that consists of only 1 group. The resulting dataframe is saved in the variable ```df_model_output_1_group```, but also in a .csv file in your current working directory. If you want to open the dataframe again later from the .csv file, use the [read_csv()](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) method of the Pandas dataframe as follows:\n",
    "\n",
    "```my_dataframe = pandas.read_csv(\"my_filename.csv\")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c713a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:50:05.845831Z",
     "start_time": "2024-08-30T09:50:05.838438Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_single_sim():\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    context_model = ContextModel(test_params[\"n_agents\"], test_params[\"n_concepts\"], test_params[\"n_bits\"], \n",
    "                                 test_params[\"n_groups\"], test_params[\"initial_degree_of_overlap\"], test_params[\"n_steps\"])\n",
    "\n",
    "    for i in range(test_params[\"n_steps\"]+1):  # set up = year 0 + x years\n",
    "        print(i)\n",
    "        context_model.step()\n",
    "\n",
    "    print(\"Simulation(s) took %s minutes to run\" % round(((time.time() - start_time) / 60.), 2))  # ADDED BY MW\n",
    "\n",
    "    df_model_output = context_model.datacollector.get_model_vars_dataframe()\n",
    "    ## alternative option for the agents is get_agent_vars_dataframe(), returns ['Step', 'AgentID', 'neighborhood', 'language', 'prop iconicity']\n",
    "    \n",
    "    return df_model_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eed942",
   "metadata": {},
   "source": [
    "First, let's use the run_single_sim() function to run a simulation with 1 group, and name the dataframe accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1180cd5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:50:14.297378Z",
     "start_time": "2024-08-30T09:50:07.364358Z"
    }
   },
   "outputs": [],
   "source": [
    "################# PARAMETER SETTINGS: ################# \n",
    "\n",
    "test_params = dict(\n",
    "    n_concepts=10, # int: number of concepts\n",
    "    n_bits=10,  # int: number of bits (determining length of forms and culturally-salient feature vectors)\n",
    "    n_agents=10, # int: number of agents in the population\n",
    "    n_groups=1,  # determines how many different semantic groups there are\n",
    "    initial_degree_of_overlap=0.9,  # degree of overlap between the form and meaning components\n",
    "    n_steps=2000  # number of timesteps to run the simulation for (called \"model stages\" in the paper)\n",
    ")\n",
    "\n",
    "df_model_output_1_group = run_single_sim()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1475bc7",
   "metadata": {},
   "source": [
    "And we can also save the resulting dataframe to a .csv file, to make sure we can open it again later, in another session (i.e., after this notebook stops running):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c90a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:50:14.369267Z",
     "start_time": "2024-08-30T09:50:14.324376Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_save_as = \"n_concepts_\"+str(test_params[\"n_concepts\"])+\"_n_bits_\"+str(test_params[\"n_bits\"])+\"_n_agents_\"+str(test_params[\"n_agents\"])+\"_n_groups_\"+str(test_params[\"n_groups\"])+\"_overlap_\"+str(test_params[\"initial_degree_of_overlap\"])+\"_n_steps_\"+str(test_params[\"n_steps\"])\n",
    "df_model_output_1_group = pd.DataFrame(df_model_output_1_group.to_records())  # gets rid of multiindex\n",
    "df_model_output_1_group.to_csv(f\"{csv_save_as}.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc342f07",
   "metadata": {},
   "source": [
    "Let's first inspect the resulting dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe32b13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:50:16.169192Z",
     "start_time": "2024-08-30T09:50:16.145379Z"
    }
   },
   "outputs": [],
   "source": [
    "df_model_output_1_group\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8104345",
   "metadata": {},
   "source": [
    "Now, we can run a similar simulation, but for a population that consists of 10 groups (where each group has different culturally salient features for each concept), by changing the value of the \"n_groups\" parameter in the test_params dictionary. And let's give the resulting dataframe a different name, accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846c52c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:50:22.516348Z",
     "start_time": "2024-08-30T09:50:17.788521Z"
    }
   },
   "outputs": [],
   "source": [
    "################# PARAMETER SETTINGS: ################# \n",
    "\n",
    "test_params = dict(\n",
    "    n_concepts=10, # int: number of concepts\n",
    "    n_bits=10,  # int: number of bits (determining length of forms and culturally-salient feature vectors)\n",
    "    n_agents=10, # int: number of agents in the population\n",
    "    n_groups=10,  # determines how many different semantic groups there are\n",
    "    initial_degree_of_overlap=0.9,  # degree of overlap between the form and meaning components\n",
    "    n_steps=2000  # number of timesteps to run the simulation for (called \"model stages\" in the paper)\n",
    ")\n",
    "\n",
    "df_model_output_10_groups = run_single_sim()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbdcbf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:50:23.309814Z",
     "start_time": "2024-08-30T09:50:23.282767Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_save_as = \"n_concepts_\"+str(test_params[\"n_concepts\"])+\"_n_bits_\"+str(test_params[\"n_bits\"])+\"_n_agents_\"+str(test_params[\"n_agents\"])+\"_n_groups_\"+str(test_params[\"n_groups\"])+\"_overlap_\"+str(test_params[\"initial_degree_of_overlap\"])+\"_n_steps_\"+str(test_params[\"n_steps\"])\n",
    "df_model_output_10_groups = pd.DataFrame(df_model_output_10_groups.to_records())  # gets rid of multiindex\n",
    "df_model_output_10_groups.to_csv(f\"{csv_save_as}.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e27d056",
   "metadata": {},
   "source": [
    "Let's again inspect the resulting dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a14a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:50:24.878826Z",
     "start_time": "2024-08-30T09:50:24.863957Z"
    }
   },
   "outputs": [],
   "source": [
    "df_model_output_10_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e61766",
   "metadata": {},
   "source": [
    "## Plotting what happens inside language games (1 group vs. 10 groups)\n",
    "\n",
    "The code below creates plots like the ones in Figures 7 and 8 in Mudd et al. (2022), showing what happened in the language games in the two simulations we ran above. Remember that these two simulations differ only in one parameter: the number of groups (```n_groups```), which determines which set of culturally salient features an agent has. The plots that are created below show the proportion of language game outcomes (i.e., how often pairs of agents achieved _form success_, _culturally salient features success_ or ended up doing a _bit update_). The resulting plots are shown below the code cell, but also saved as .png files to your current working directory (see lines using ```plt.savefig()``` method below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f06758",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:50:26.245038Z",
     "start_time": "2024-08-30T09:50:26.227599Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_single_sim(dataframe_single_sim, plot_title, filename):\n",
    "\n",
    "    # colormap\n",
    "    cmap = plt.cm.viridis\n",
    "    cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "\n",
    "    # set up 2 column figure\n",
    "    fig, (ax0, ax1) = plt.subplots(ncols=2, constrained_layout=True)\n",
    "    fig.set_size_inches(9,3)\n",
    "\n",
    "    # FIG 1 GROUP EXAMPLE RUN\n",
    "    # 1 group, 10 stages on ax0\n",
    "\n",
    "    # Uncomment the line below if you want to load in your dataframe from a .csv file:\n",
    "    # model_output = pd.read_csv(\"\", index_col=0)\n",
    "\n",
    "    model_output = dataframe_single_sim\n",
    "\n",
    "    model_output = model_output[['current_step', 'lg_form_success', 'lg_meaning_success', 'lg_bit_update']]\n",
    "    model_output = model_output.rename(columns={\"lg_form_success\": \"form_success\", \"lg_meaning_success\": \"culturally_salient_features_success\", \"lg_bit_update\": \"update_bit\"})\n",
    "    model_output = model_output.iloc[1:11]\n",
    "    model_output[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\"]] = model_output[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\"]].div(10, axis=0)\n",
    "\n",
    "    # https://www.python-graph-gallery.com/13-percent-stacked-barplot\n",
    "    # From raw value to percentage\n",
    "    totals = [i+j+k for i, j, k in zip(model_output['update_bit'], model_output['culturally_salient_features_success'], model_output['form_success'])]\n",
    "    bit_bars = [i / j for i,j in zip(model_output['update_bit'], totals)]\n",
    "    features_bars = [i / j for i,j in zip(model_output['culturally_salient_features_success'], totals)]\n",
    "    form_bars = [i / j for i,j in zip(model_output['form_success'], totals)]\n",
    "\n",
    "    steps = range(model_output[\"current_step\"].min(), model_output[\"current_step\"].max() + 1)  # min, max steps in df\n",
    "    ax0.bar(steps, bit_bars, color=cmaplist[0], width=1, edgecolor=\"none\", label=\"bit update\")  # Create green Bars\n",
    "    ax0.bar(steps, features_bars, bottom=bit_bars, color=cmaplist[128], width=1, edgecolor=\"none\", label=\"CS features success\")  # Create orange Bars\n",
    "    ax0.bar(steps, form_bars, bottom=[i + j for i, j in zip(bit_bars, features_bars)], color=cmaplist[-1], width=1, edgecolor=\"none\", label=\"form success\")  # Create blue Bars\n",
    "\n",
    "    # axes\n",
    "    ax0.set_xlabel(\"Model stage\", fontsize=15)\n",
    "    ax0.set_ylim(0,1)\n",
    "    ax0.set_ylabel(\"Proportion\", fontsize=15)\n",
    "    ax0.set_xticks(np.arange(1, 11, 1))\n",
    "\n",
    "\n",
    "    # 1 group, 2000 stages on ax1\n",
    "\n",
    "    # Uncomment the line below if you want to load in your dataframe from a .csv file:\n",
    "    # model_output = pd.read_csv(\"\", index_col=0)\n",
    "\n",
    "    model_output = dataframe_single_sim\n",
    "\n",
    "    model_output = model_output[['current_step', 'lg_form_success', 'lg_meaning_success', 'lg_bit_update']]\n",
    "    model_output = model_output.rename(columns={\"lg_form_success\": \"form_success\", \"lg_meaning_success\": \"culturally_salient_features_success\", \"lg_bit_update\": \"update_bit\"})\n",
    "    model_output = model_output.drop([0])\n",
    "    model_output[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\"]] = model_output[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\"]].div(10, axis=0)\n",
    "\n",
    "    # add column with value for groups of 50 (1-50, 51-100, etc.)\n",
    "    for index, row in model_output.iterrows():\n",
    "        model_output.at[index, \"hist_block\"] = int(index/50)\n",
    "\n",
    "    model_output_grouped = model_output.groupby([\"hist_block\"]).mean()\n",
    "    model_output_grouped[\"original_index\"] = model_output_grouped.index * 50\n",
    "    model_output = model_output_grouped[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\", \"original_index\"]]\n",
    "\n",
    "    # https://www.python-graph-gallery.com/13-percent-stacked-barplot\n",
    "    # From raw value to percentage\n",
    "    totals = [i+j+k for i, j, k in zip(model_output['update_bit'], model_output['culturally_salient_features_success'], model_output['form_success'])]\n",
    "    bit_bars = [i / j for i,j in zip(model_output['update_bit'], totals)]\n",
    "    features_bars = [i / j for i,j in zip(model_output['culturally_salient_features_success'], totals)]\n",
    "    form_bars = [i / j for i,j in zip(model_output['form_success'], totals)]\n",
    "\n",
    "    steps = range(int(model_output.index.min()), int(model_output.index.max() + 1))  # min, max steps in df\n",
    "    ax1.bar(steps, bit_bars, color=cmaplist[0], width=1, edgecolor=\"none\", label=\"bit update\")  # Create green Bars\n",
    "    ax1.bar(steps, features_bars, bottom=bit_bars, color=cmaplist[128], width=1, edgecolor=\"none\", label=\"CS features success\")  # Create orange Bars\n",
    "    ax1.bar(steps, form_bars, bottom=[i + j for i, j in zip(bit_bars, features_bars)], color=cmaplist[-1], width=1, edgecolor=\"none\", label=\"form success\")  # Create blue Bars\n",
    "\n",
    "    # legend\n",
    "    handles, labels = ax1.get_legend_handles_labels()\n",
    "    handles = [handles[2], handles[1], handles[0]]\n",
    "    labels = [labels[2], labels[1], labels[0]]\n",
    "    ax1.legend(handles, labels, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    # axes\n",
    "    ax1.set_xlabel(\"Model stage\", fontsize=15)\n",
    "    ax1.set_ylim(0,1)\n",
    "    ax1.set_ylabel(\"\", fontsize=15)\n",
    "    ax1.set_xticks(np.arange(0, 41, step=10))\n",
    "    ax1.set_xticklabels([0,500,1000,1500,2000])\n",
    "\n",
    "    plt.suptitle(plot_title, fontsize=18, x=0.4, y=1.1)\n",
    "\n",
    "    plt.savefig(filename, dpi=1000, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59658938",
   "metadata": {},
   "source": [
    "Let's plot the 1 group results and the 10 groups results directly below each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360f43ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:50:32.824296Z",
     "start_time": "2024-08-30T09:50:27.654286Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plot_single_sim(df_model_output_1_group, \"1 group\", \"barplot_1_group.png\")\n",
    "\n",
    "plot_single_sim(df_model_output_10_groups, \"10 groups\", \"barplot_10_groups.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f942b161",
   "metadata": {},
   "source": [
    "**Exercise 3:**\n",
    "\n",
    "Run two simulations, both with ```n_groups = 5```, in which instead of varying the number of groups in the population, you instead vary the ```initial_degree_of_overlap``` parameter. Try out what happens with the following settings:\n",
    "- ```initial_degree_of_overlap``` = 0.3\n",
    "- ```initial_degree_of_overlap``` = 0.9\n",
    "\n",
    "Plot what happens in the language games, just like we did above. Run the simulations a couple of times, and plot the results, to see what happens. Is there a simulation run in which you see a difference between the two conditions in the plots? If so, try and explain that difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf19043",
   "metadata": {},
   "source": [
    "I've copy-pasted the code cell with parameter settings from the top of the notebook below, so that you can easily change the parameters as needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef330f1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:50:35.518932Z",
     "start_time": "2024-08-30T09:50:35.515992Z"
    }
   },
   "outputs": [],
   "source": [
    "################# PARAMETER SETTINGS: ################# \n",
    "\n",
    "test_params = dict(\n",
    "    n_concepts=10, # int: number of concepts\n",
    "    n_bits=10,  # int: number of bits (determining length of forms and culturally-salient feature vectors)\n",
    "    n_agents=10, # int: number of agents in the population\n",
    "    n_groups=1,  # determines how many different semantic groups there are\n",
    "    initial_degree_of_overlap=0.9,  # degree of overlap between the form and meaning components\n",
    "    n_steps=2000  # number of timesteps to run the simulation for (called \"model stages\" in the paper)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b01bf30",
   "metadata": {},
   "source": [
    "**Answer to exercise 3):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33512da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T12:34:41.915407Z",
     "start_time": "2022-10-12T12:34:38.063219Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068d32d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T12:34:50.184360Z",
     "start_time": "2022-10-12T12:34:43.931712Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac5696",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T12:34:56.067382Z",
     "start_time": "2022-10-12T12:34:51.661739Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26999104",
   "metadata": {},
   "source": [
    "## Running a batch of simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8600f5",
   "metadata": {},
   "source": [
    "Below we first need to set some extra parameters in order to:\n",
    "- Run several conditions in which we vary the number of groups in the population (while keeping all other parameter settings constant)\n",
    "- Run a number of independent simulation runs per condition (i.e., per setting of the ```n_groups``` parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a1a7fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:50:40.973618Z",
     "start_time": "2024-08-30T09:50:40.970311Z"
    }
   },
   "outputs": [],
   "source": [
    "################# MORE PARAMETER SETTINGS: ################# \n",
    "\n",
    "# The code below turns n_groups into a variable parameter; to run several different settings in a batch run\n",
    "variable_params = dict(n_groups=[1, 2, 5, 10]) # the different numbers of groups in the population to simulate separately\n",
    "# need to do this because otherwise fixed_parameters overwrites variable_parameters:\n",
    "fixed_params = dict((k, v) for (k, v) in test_params.items() if k not in variable_params)\n",
    "\n",
    "n_iterations = 20  # number of independent simulation runs per condition (called \"repetitions\" in the paper)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0512596b",
   "metadata": {},
   "source": [
    "In order to run a batch run with 4 different group sizes in a reasonable amount of time, we have to lower the ```n_iterations``` parameter (which determines how many independent simulation runs are run per condition) compared to the original paper. Mudd et al. (2022) used 100 runs per condition. This gives them a solid idea of how much variation there is between independent simulation runs (as some parts of the simulations are probabilistic/stochastic in nature). In the code cell above, I set ```n_iterations``` to 20. With this setting, the batch run below took about 5 minutes to run on my Macbook Pro which has a 2,6 GHz 6-Core Intel Core i7 processor. If the batch run still hasn't finished running after 10 minutes on your computer, consider decreasing the ```n_iterations``` parameter further; for example to 10.\n",
    "\n",
    "Or, if you want to get a better idea of the variability between runs, and you have some time to wait for the simulations to finish running, you can increase the ```n_iterations``` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2ed3a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:50:42.477800Z",
     "start_time": "2024-08-30T09:50:42.474709Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_batch_runner(model, variable_parameters=None, **kwargs):\n",
    "    \"\"\" function created to circumvent problem of not having any variable_parameters\n",
    "    even though mesa documentation says default of variable_parameters=None\n",
    "    there is an error if None is passed... Yannick wrote mesa to fix this\"\"\"\n",
    "    if not variable_parameters:\n",
    "        return FixedBatchRunner(model, parameters_list=[], **kwargs)\n",
    "    else:\n",
    "        return BatchRunner(model, variable_parameters=variable_parameters, **kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7be62a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:50:42.916190Z",
     "start_time": "2024-08-30T09:50:42.910667Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_batch_sims(test_params, variable_params, fixed_params, n_iterations):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    br = create_batch_runner(ContextModel,\n",
    "                         variable_parameters=variable_params,\n",
    "                         fixed_parameters=fixed_params,\n",
    "                         iterations=n_iterations,\n",
    "                         max_steps=test_params[\"n_steps\"]+1,  # set up = year 0 + x years\n",
    "                         model_reporters={\"Data Collector\": lambda m: m.datacollector})\n",
    "\n",
    "    br.run_all()\n",
    "    br_df = br.get_model_vars_dataframe()  # df with params + data collector per run\n",
    "    br_step_data = pd.DataFrame()\n",
    "\n",
    "    for idx, row in br_df.iterrows():\n",
    "        assert isinstance(row[\"Data Collector\"], DataCollector)\n",
    "        i_run_data = row[\"Data Collector\"].get_model_vars_dataframe()\n",
    "        i_run_data['idx'] = idx\n",
    "        br_step_data = br_step_data.append(i_run_data, ignore_index=True)\n",
    "\n",
    "    final_df = br_step_data.join(br_df.drop(\"Data Collector\", axis=\"columns\"), on='idx')\n",
    "    final_df = final_df.rename(columns={\"idx\": \"run\"})\n",
    "    \n",
    "    print(\"Simulation(s) took %s minutes to run\" % round(((time.time() - start_time) / 60.), 2))\n",
    "    \n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9495eed5",
   "metadata": {},
   "source": [
    "We can use the run_batch_sims() function (and save the resulting dataframe to a .csv file) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ede9e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:57:58.129674Z",
     "start_time": "2024-08-30T09:50:44.322730Z"
    }
   },
   "outputs": [],
   "source": [
    "final_df = run_batch_sims(test_params, variable_params, fixed_params, n_iterations)\n",
    "\n",
    "final_df.to_csv(f\"{csv_save_as}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03af96d",
   "metadata": {},
   "source": [
    "Let's first inspect the resulting dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88861ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:58:08.094696Z",
     "start_time": "2024-08-30T09:58:08.071717Z"
    }
   },
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b6a3bd",
   "metadata": {},
   "source": [
    "## Plotting the results of a batch of simulations\n",
    "\n",
    "The code below plots the degrees of lexical variability and iconicity over time for each parameter setting included in your batch run. Given that we have now run 20 independent simulation runs per condition, the plots below show both the mean (dark line) and standard deviations (shaded areas) over those 20 independent runs. These plots are the same as Figure 10 in Mudd et al. (2022)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961ac019",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:58:11.404377Z",
     "start_time": "2024-08-30T09:58:11.393207Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_batch_sims(dataframe_batch_sims, filename, condition):\n",
    "\n",
    "    # colormap\n",
    "    cmap = plt.cm.viridis\n",
    "    cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "\n",
    "    # set up 2 column figure\n",
    "    fig, (ax0, ax1) = plt.subplots(ncols=2, constrained_layout=True)\n",
    "    fig.set_size_inches(9, 4)\n",
    "\n",
    "    # N_GROUPS\n",
    "    # model_output = pd.read_csv(\"\", index_col=0)  # pop_iconicity, pop_lex_var, year, run\n",
    "    model_output = dataframe_batch_sims\n",
    "\n",
    "    model_output = model_output[[\"pop_iconicity\", \"pop_lex_var\", \"current_step\", \"run\", condition]]\n",
    "\n",
    "    # lexical variability\n",
    "    sns.set(style='whitegrid')\n",
    "    sns.lineplot(data=model_output, x=\"current_step\", y=\"pop_lex_var\", hue=condition, ci=\"sd\", palette=[cmaplist[0], cmaplist[85], cmaplist[170], cmaplist[-1]], ax=ax0)  # len(cmaplist)/3 = 85.33\n",
    "    # axes\n",
    "    ax0.set_title(\"Lexical variability\", fontsize=18)\n",
    "    ax0.set_xlim(0,2000)\n",
    "    ax0.set_xlabel(\"Model stage\", fontsize=15)\n",
    "    ax0.set_ylim(0,1)\n",
    "    ax0.set_ylabel(\"Mean lexical variability\", fontsize=15)\n",
    "    ax0.get_legend().remove()\n",
    "\n",
    "    # iconicity\n",
    "    sns.set(style='whitegrid')\n",
    "    sns.lineplot(data=model_output, x=\"current_step\", y=\"pop_iconicity\", hue=condition, ci=\"sd\", palette=[cmaplist[0], cmaplist[85], cmaplist[170], cmaplist[-1]], ax=ax1)\n",
    "    # axes\n",
    "    ax1.set_title(\"Iconicity\", fontsize=18)\n",
    "    ax1.set_xlim(0,2000)\n",
    "    ax1.set_xlabel(\"Model stage\", fontsize=15)\n",
    "    ax1.set_ylim(0,1)\n",
    "    ax1.set_ylabel(\"Mean iconicity\", fontsize=15)\n",
    "    ax1.legend(loc='center left', bbox_to_anchor=(1, 0.5), title=condition)  # Add a legend\n",
    "\n",
    "    plt.savefig(filename, dpi=1000, bbox_inches=\"tight\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f9717d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T09:58:19.945415Z",
     "start_time": "2024-08-30T09:58:14.307779Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "condition = \"n_groups\"\n",
    "\n",
    "plot_batch_sims(final_df, \"n_groups_plt.png\", condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1084c5dc",
   "metadata": {},
   "source": [
    "**Exercise 4:**\n",
    "\n",
    "Perform a batch run like the one above, but instead of varying the ```n_groups``` parameter, vary the  ```initial_degree_of_overlap``` parameter instead, using the following values:\n",
    "- ```initial_degree_of_overlap = 0.1```\n",
    "- ```initial_degree_of_overlap = 0.3```\n",
    "- ```initial_degree_of_overlap = 0.6```\n",
    "- ```initial_degree_of_overlap = 0.9```\n",
    "\n",
    "Throughout each of these simulations, fix the value of the ```n_groups``` parameter at 5.\n",
    "\n",
    "Plot the results of your batch run using the plotting code above (which plots the degree of lexical variability and the degree of iconicity for each of the four different parameter settings together).\n",
    "\n",
    "**a)** Describe the differences that you see as a result of the different settings and ```initial_degree_of_overlap``` parameter, and try to explain them. \n",
    "\n",
    "**b)** (Conceptual question:) In what ways is manipulating the ```initial_degree_of_overlap``` parameter in this model different from manipulating the ```n_groups``` parameter? And in what ways might they be getting at the same thing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9873947",
   "metadata": {},
   "source": [
    "To help you along with the first step, I've copy-pasted the two code cells with parameter settings below. The first code cell allows you to change the fixed parameters, and the second code cells allows you to change the variable parameters, which should be varied in the batch run. In the simulation above, the ```variable_params``` dictionary was used to vary the ```n_groups``` parameter, but for Exercise 4, you want to vary the ```initial_degree_of_overlap``` parameter instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedcf4cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T10:11:00.369200Z",
     "start_time": "2024-08-30T10:11:00.357772Z"
    }
   },
   "outputs": [],
   "source": [
    "################# PARAMETER SETTINGS: ################# \n",
    "\n",
    "test_params = dict(\n",
    "    n_concepts=10, # int: number of concepts\n",
    "    n_bits=10,  # int: number of bits (determining length of forms and culturally-salient feature vectors)\n",
    "    n_agents=10, # int: number of agents in the population\n",
    "    n_groups=1,  # determines how many different semantic groups there are\n",
    "    initial_degree_of_overlap=0.9,  # degree of overlap between the form and meaning components\n",
    "    n_steps=2000  # number of timesteps to run the simulation for (called \"model stages\" in the paper)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b0ffbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T10:11:01.764959Z",
     "start_time": "2024-08-30T10:11:01.760394Z"
    }
   },
   "outputs": [],
   "source": [
    "################# MORE PARAMETER SETTINGS: ################# \n",
    "\n",
    "# The code below turns n_groups into a variable parameter; to run several different settings in a batch run\n",
    "variable_params = dict(n_groups=[1, 2, 5, 10]) # the different numbers of groups in the population to simulate separately\n",
    "# need to do this because otherwise fixed_parameters overwrites variable_parameters:\n",
    "fixed_params = dict((k, v) for (k, v) in test_params.items() if k not in variable_params)\n",
    "\n",
    "n_iterations = 20  # number of independent simulation runs per condition (called \"repetitions\" in the paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffedc0b",
   "metadata": {},
   "source": [
    "**Answer to exercise 4.a):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441111e5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2644a415",
   "metadata": {},
   "source": [
    "**Answer to exercise 4.b):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3ea3ba",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95d148eb",
   "metadata": {},
   "source": [
    "If you're working in a virtual environment, **don't forget to deactivate your virtual environment** using the ```deactivate``` command."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
