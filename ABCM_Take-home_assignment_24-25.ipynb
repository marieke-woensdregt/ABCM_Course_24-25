{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5afcc25",
   "metadata": {},
   "source": [
    "# Take-home assignment: Agent-based Cognitive Modelling\n",
    "\n",
    "Please complete each of the conceptual questions in a markdown cell (in written text), and each of the coding questions using code cells (in combination with markdown cells if a written part is also required for answering the question).\n",
    "\n",
    "It is important that you complete each of the exercises in this take-home assignment **individually**. If we see signs of answers being shared between students, we will investigate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c1948f",
   "metadata": {},
   "source": [
    "**Info about required package versions:**\n",
    "\n",
    "The coding exercises in this take-home assignment make use of code from Computer Lab 1 (which requires the ```tomsup``` package), and code from Computer Lab 4 (which requires an older version of the ```mesa``` package). Specifically, Exercise 3 makes use of code from Computer Lab 1, and Exercises 7 and 9 make use of code from Computer Lab 4. For Exercise 6, you will need to inspect code from Computer Lab 3, but will not actually have to run any code from Computer Lab 3 inside this notebook in order to complete this take-home assignment.\n",
    "If you have previously installed the relevant versions of the packages in a virtual environment for this course in order to be able to do the Computer Lab exercises, you should hopefully be able to run the code in this notebook using the same virtual environment.\n",
    "\n",
    "Below is an overview of the package requirements we have run into for the computer labs of this course so far:\n",
    "\n",
    "- **Python version for ```tomsup```:** When installing ```tomsup```, it will automatically install the required version of ```numpy```. However, the required version of ```numpy``` is no longer supported by newer versions of Python. Python version 3.7 has been shown to work (I myself used Python version 3.7.4 to run Computer Lab 1).\n",
    "- **pandas version for ```tomsup```:** The ```tomsup``` package also requires an older version of ```pandas``` to work. We know that version 1.3.5 of ```pandas``` definitely works. (With newer versions of ```pandas```, you might run into an error when using the .compete() method of the AgentGroup class.)\n",
    "\n",
    "- **mesa version:** The code from Computer Lab 4 requires an older version of the ```mesa``` package. We know that it works with version 0.9.0 of ```mesa```. (With newer versions of ```mesa```, you might run into an error when trying to run the import statement \"from mesa.batchrunner import BatchRunner, FixedBatchRunner\".)\n",
    "- **pandas version for mesa:** The code from Computer Lab 4 also requires an older version of the ```pandas``` package. We know that version 1.3.5 works here as well (same version as for the ```tomsup``` package). (With newer versions of ```pandas```, you might run into an error with the ```run_batch_sims()``` function, which assumes that a pandas dataframe has a .append() method.)\n",
    "\n",
    "**In case you don't manage to get this to run with a local environment on your own machine:** We created a Google Colab version of this notebook which contains a code cell that installs all the required package versions and makes sure the notebook is run in the right version of Python. So you can also do the take-home assignment in that Google Colab version. You can find the Google Colab version of the take-home assignment here: <span class=\"burk\">**Add link**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2343fca",
   "metadata": {},
   "source": [
    "## Exercise 1 (Conceptual question):\n",
    "\n",
    "This question is about agent-based cognitive modelling in general.\n",
    "\n",
    "Below are four research questions. For each of these, write down: \n",
    "- Whether or not you think _agent-based_ modelling would be a sensible approach to address that research question, **and explain why**. \n",
    "- Whether or not you think _cognitive_ modelling would be a sensible approach to address that research question, **and explain why**.\n",
    "\n",
    "**Note** that a model can be both agent-based _and_ cognitive, or just agent-based without being cognitive, or just cognitive without being agent-based.\n",
    "\n",
    "1. \n",
    "    - **Background:** [Categorisation](https://en.wikipedia.org/wiki/Cognitive_categorization) is the cognitive capacity to classify objects, events or ideas into groups of things that 'belong together'. Two competing theories of how human categorise things are [Exemplar Theory](https://en.wikipedia.org/wiki/Exemplar_theory) and [Prototype Theory](https://en.wikipedia.org/wiki/Prototype_theory). In simple terms, _exemplar-based_ categorisation means: if a novel stimulus is more similar to other dogs I've seen before than to other cats I've seen before, it's probably a dog. While _feature-based_ categorisation means: if the novel stimulus shares a lot of features with the _prototypical_ dog (e.g., it (i) barks, (ii) has four legs, (iii) has a wagging tail), it's probably a dog.\n",
    "    - **Research question:** Is categorisation in humans exemplar-based or feature-based? \n",
    "\n",
    "\n",
    "2. Do more extreme ideas spread through a population more quickly than more moderate ideas?\n",
    "\n",
    "\n",
    "3. How do two individuals coordinate a _joint action_ (for example, a task like moving a sofa together)?\n",
    "\n",
    "\n",
    "4. How does eye colour spread through a population? (Assuming, for example, that the allele for blue eyes is recessive and the allele for brown eyes is dominant.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71be2581",
   "metadata": {},
   "source": [
    "**Answer to exercise 1):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16db827",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e04c9aa",
   "metadata": {},
   "source": [
    "## Exercise 2 (Conceptual question):\n",
    "\n",
    "This question is about [Game Theory](https://en.wikipedia.org/wiki/Game_theory) and pay-off matrices as a representation of social coordination situations.\n",
    "\n",
    "**Imagine the following world:**\n",
    "In this world, all that matters is (i) getting to enjoy nice homemade food, and (ii) minimising the amount of time and effort you yourself put in to get to enjoy that nice homemade food. We make the following five assumptions:\n",
    "\n",
    "1. A homemade dish is always more enjoyable to eat than a snack bought at the supermarket.\n",
    "2. It's nicer to enjoy someone else's homemade dish (because it's new and surprising) than to eat your own homemade dish.\n",
    "3. The people in this world do not get joy out of seeing someone else enjoying the food they made.\n",
    "4. The people in this world do not get joy out of being complimented on the food they made.\n",
    "5. The people in this world do not care about social norms about what one is supposed or expected to bring to a [potluck dinner](https://en.wikipedia.org/wiki/Potluck).\n",
    "\n",
    "\n",
    "**Now imagine the following situation:**\n",
    "\n",
    "Person A and Person B who live in this world are both going to a [potluck dinner](https://en.wikipedia.org/wiki/Potluck). They both have to make a decision about whether to put the time and effort into making a nice homemade dish, or whether to just buy something simple at the supermarket and bring that, without knowing what the other person will bring (something nice or something simple). If Person A brings something homemade that they put some time and effort into, Person B will feel it's worth it to also have put time and effort into making their own homemade dish, because they get to enjoy Person A's dish as well. However, if Person A just brings something simple from the supermarket, Person B will be disappointed if they put time and effort into making their homemade dish, and they would have preferred to spend that time doing something else.\n",
    "\n",
    "**Question:**\n",
    "\n",
    "**a)** Below is an empty pay-off matrix (game-theory style). Translate the situation above to a pay-off matrix, by filling in each of the cells in the table below, according to the situation described above. Replace each of the A's and B's in the table with the pay-off values for Person A and Person B. You may only use the following values in the pay-off matrix: $[0, 1, 2, 3]$ (but you may use each value as many or as few times as you need).\n",
    "\n",
    "**b)** For each of the cells in your table, explain in words how you got to the values you put in that cell; what was your reasoning?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78436a3",
   "metadata": {},
   "source": [
    "| B (Other person):     | Homemade dish | Supermarket snack |\n",
    "|-----------------------|---------------|-------------------|\n",
    "| **A (You):**          |               |                   |\n",
    "| **Homemade dish**     |      A, B     |        A, B       |\n",
    "| **Supermarket snack** |      A, B     |        A, B       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702e2e44",
   "metadata": {},
   "source": [
    "**Answer to exercise 2a):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410aa232",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43a0faab",
   "metadata": {},
   "source": [
    "**Answer to exercise 2b):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ec5317",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5c445b0",
   "metadata": {},
   "source": [
    "## Exercise 3 (Coding question):\n",
    "\n",
    "\n",
    "Use the tomsup package to simulate the following situation:\n",
    "\n",
    "- agent0 = A ```'1-ToM'``` agent with default parameter settings\n",
    "- agent1 = A ```'2-ToM'``` agent with default parameter settings\n",
    "- game = ```'party'```\n",
    "- environment = ```'round-robin'```\n",
    "- n_sim = 10\n",
    "\n",
    "Run 10 simulations of this interaction for a number of rounds that seems reasonable to you, and use the ```group.plot_p_k()``` method to plot how agent1's belief about agent0's ToM level changes over time. (The three code cells below make a start by loading in the relevant packages.)\n",
    "\n",
    "Find out whether there is a certain number of rounds after which each of the 10 simulations reaches a point where agent1 has a fully accurate model of their opponent's _k_-level (and has reached maximum certainty about that).\n",
    "\n",
    "Show a plot to back up your answer, and also explain your answer fully in words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae95a74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:41:24.590596Z",
     "start_time": "2024-10-21T13:41:22.911875Z"
    }
   },
   "outputs": [],
   "source": [
    "import tomsup as ts\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1641b5f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T13:41:26.345047Z",
     "start_time": "2024-10-21T13:41:26.323860Z"
    }
   },
   "outputs": [],
   "source": [
    "party = ts.PayoffMatrix(name='party')\n",
    "\n",
    "print(party)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90adbea",
   "metadata": {},
   "source": [
    "**Answer to exercise 3):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b08f522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab2ee8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9debb0b4",
   "metadata": {},
   "source": [
    "## Exercise 4 (Conceptual question):\n",
    "\n",
    "This question is about both the Waade et al. (2022) and the de Weerd et al. (2015) model, and the comparison between these two models.\n",
    "\n",
    "In both the Waade et al. (2022) model and the de Weerd et al. (2015) model, the $k$-ToM agent has a belief about the $k$-level of the agent they're interacting with, and updates this belief over the course of the interactions. Describe **5** major similarities and/or differences in how this belief-updating about the other agent's $k$-level works in these two different models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc5faf3",
   "metadata": {},
   "source": [
    "**Answer to exercise 4):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac51c1ad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79e19d1d",
   "metadata": {},
   "source": [
    "## Exercise 5 (Conceptual question):\n",
    "\n",
    "This question is about the de Weerd et al. (2015) paper and the Madsen et al. (2019) paper.\n",
    "\n",
    "As we've discussed in the lectures and read in the Madsen et al. (2019) paper, agent-based models can be used to _calibrate_ and/or _validate_ cognitive models.\n",
    "\n",
    "**a)** What are the observations and/or hypotheses that the paper by de Weerd et al. (2015) starts from?\n",
    "\n",
    "**b)** To what extent do you think that the cognitive model and the simulation results presented by de Weerd et al. (2015) can account for or support these observations and/or hypotheses? Explain why.\n",
    "\n",
    "**c)** What further steps do you think would be useful for calibrating and/or validating the cognitive model presented by de Weerd et al. (2015), given the observations and/or hypotheses they started from? (You can think of computational modelling work, experimental work, observational work, or any combination thereof.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6656dee9",
   "metadata": {},
   "source": [
    "**Answer to exercise 5.a):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5abc45",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de8489d7",
   "metadata": {},
   "source": [
    "**Answer to exercise 5.b):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ffb22a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81e0c0d0",
   "metadata": {},
   "source": [
    "**Answer to exercise 5.c):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843a06db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da486c7e",
   "metadata": {},
   "source": [
    "## Exercise 6 (Implementation/code-related question):\n",
    "\n",
    "This question is about the Cuskley et al. (2018) model.\n",
    "\n",
    "Imagine that you want to extend the Cuskley et al. (2018) model to look at the effect of social network structure on morphological complexity. For an idea of what such a social network structure might look like, see this Wikipedia page on [social networks](https://en.wikipedia.org/wiki/Social_network), and/or the paper by Raviv et al. (2020) in the Reference list below. \n",
    "\n",
    "For this exercise, you're going to describe **in words** how you would have to adapt the code of Computer Lab 3 to make it ready to allow you to specify such a social network structure for a population. **So you do not have to do any programming for this exercise.** More specifically, answer questions **a)**, **b)** and **c)** below.\n",
    "\n",
    "**a)** How could you represent a social network structure for a population of agents (in a way that would be compatible with Python code)? (You do not need to think about how you would _generate_ a social network structure of a particular type; you only need to think about how you would _represent_ it.)\n",
    "\n",
    "**b)** Building on your answer to question a, What would you need to add or adapt to the code from Computer Lab 3 in order to be able to initialise a population with a specified type of social network structure? Describe in words which class(es) and/or function(s) you would adapt, and how (e.g., do you need to add an attribute to a class? Add a variable inside a function? Change or add lines of code inside a function or method? Or add a completely new function? etc.).\n",
    "\n",
    "**c)** Building on your answers to questions a and b, what would you have to add or adapt to the code to make sure that agents only interact with agents they are connected to, according to the social network structure?\n",
    "\n",
    "\n",
    "**References:**\n",
    "\n",
    "Raviv, L., Meyer, A., & Lev-Ari, S. (2020). The Role of Social Network Structure in the Emergence of Linguistic Structure. Cognitive Science, 44(8), e12876. https://doi.org/10.1111/cogs.12876"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dc6855",
   "metadata": {},
   "source": [
    "**Answer to exercise 6.a):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de194ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6be259d0",
   "metadata": {},
   "source": [
    "**Answer to exercise 6.b):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d55d5b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e4e9e6b",
   "metadata": {},
   "source": [
    "**Answer to exercise 6.c):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ee5363",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a6db1b7",
   "metadata": {},
   "source": [
    "## Exercise 7 (Coding question):\n",
    "\n",
    "This question is about the Mudd et al. (2022) model.\n",
    "\n",
    "**Background:**\n",
    "- When a pair of interacting agents in the Mudd et al. (2022) model fails to achieve communicative success (i.e., when they achieve _neither_ form success, _nor_ culturally salient features success), the receiver does _bit update_. This process consists of the receiver making their form for the intended concept more similar to the sender's form for that concept.\n",
    "- The Mudd et al. (2022) model also allows for the specification of groups in the population, which determines whether agents share the same culturally-salient features or not (where members of the same group share the same culturally-salient features, but members of different groups do not).\n",
    "\n",
    "Imagine that you have empirical evidence that people in real life are more likely to adopt linguistic variants of other people from a group they identify with, than of people from a different group. For example, if you and I are both members of the group \"young people\", and you call something \"lit\" that I used to call \"cool\", I'm more likely to adopt your variant and also start saying \"lit\", than if I identify as a member of the group \"older people\".\n",
    "And now imagine you want to explore what happens to the dynamics of the Mudd et al. model if you add this assumption. That is, under the hypothesis that agents are more likely to adopt the form of another agent within their own group, than of agents from other groups. What would you have to change to the code of Computer Lab 4 to allow you to explore this hypothesis?\n",
    "\n",
    "**a)** Change the ```language_game_structure_extended()``` function below, such that when the agents fail to communicate successfully, the comprehender agent will do _bit update_ to make their form more similar to the producer's form with 0.8 probability if they are from the same group, and with 0.2 probability if they are from different groups.\n",
    "\n",
    "**b)** Use the code further below (from Section 1.7.2 _\"Below is the code you need for Exercise 7b:\"_ onwards), in order to test whether your new ```language_game_structure_extended()``` function works as intended. To do this, run 20 rounds of interaction between two agents from the same group, and 20 rounds of interaction between agents from two different groups, and print all the relevant information. More specifically: \n",
    "- Add print statements to print all the relevant variables inside your ```language_game_structure_extended()``` function to check that it's working as intended.\n",
    "- Write code in the designated code cell for Exercise 7b to use your new ```language_game_structure_extended()``` function to run (i) 20 interactions between a pair of agents from the same group, and (ii) 20 interactions between a pair of agents from different groups. The final code cell before Section 1.7.2.1 _\"Use the code cell below to do Exercise 7b; building on the code cells above:\"_ shows you how you can create those agents, using the ```ContextAgentSimplified()``` class.\n",
    "- Write out in words in a text cell how you can tell from the printed output that your function is (or at least seems to be, to the extent that you can tell from running 20 interactions per condition) working as intended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643e22a9",
   "metadata": {},
   "source": [
    "### Below is the code you need for Exercise 7a:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cde792",
   "metadata": {},
   "source": [
    "First, let's import the relevant packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fda468",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T14:50:59.529360Z",
     "start_time": "2024-10-21T14:50:59.522257Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from mesa import Agent, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94878fe2",
   "metadata": {},
   "source": [
    "**Answer to exercise 7.a):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3c2405",
   "metadata": {},
   "source": [
    "#### Below is the code cell you need _to adapt_ for Exercise 7a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175bbaad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T14:51:00.521461Z",
     "start_time": "2024-10-21T14:51:00.516960Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_game_structure_extended(producer, comprehender):\n",
    "    producer_concept_choice = random.choice(list(producer.language_rep))  # 1\n",
    "    form_match_answer = does_closest_form_match(producer, producer_concept_choice, comprehender)  # 2\n",
    "    if form_match_answer == False:  # 3b\n",
    "        meaning_match_answer = does_closest_meaning_match(producer, producer_concept_choice, comprehender)\n",
    "        if meaning_match_answer == False:  # 3b2\n",
    "            update_comprehender_concept(producer, producer_concept_choice, comprehender)\n",
    "            return \"3b2\"\n",
    "        else:  # 3b1\n",
    "            # None\n",
    "            return \"3b1\"\n",
    "    else:  # 3a\n",
    "        # None\n",
    "        return \"3a\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f935cba",
   "metadata": {},
   "source": [
    "#### Below are the functions that are being called by language_game_structure_extended():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276cf689",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T14:51:01.488287Z",
     "start_time": "2024-10-21T14:51:01.483104Z"
    }
   },
   "outputs": [],
   "source": [
    "def does_closest_form_match(producer, producer_concept_choice, comprehender):\n",
    "    produced_form = producer.language_rep[producer_concept_choice][1]\n",
    "\n",
    "    distance_from_produced_form = {}\n",
    "    for concept, meaning_form in comprehender.language_rep.items():\n",
    "        # compare produced concept and all comp concepts, calculate distance between each\n",
    "        distance = sum([abs(prod_bit - comp_bit) for prod_bit, comp_bit in zip(produced_form, meaning_form[1])])\n",
    "        distance_from_produced_form[concept] = distance\n",
    "\n",
    "    min_distance = min(distance_from_produced_form.values())\n",
    "    comp_closest_form_list = [concept for concept, distance in distance_from_produced_form.items() if distance == min_distance]\n",
    "    comp_chosen_form = random.choice(comp_closest_form_list)  # because there can be multiple, randomly choose from list\n",
    "\n",
    "    return producer_concept_choice == comp_chosen_form  # returns True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7a332a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T14:51:01.909720Z",
     "start_time": "2024-10-21T14:51:01.905073Z"
    }
   },
   "outputs": [],
   "source": [
    "def does_closest_meaning_match(producer, producer_concept_choice, comprehender):\n",
    "    produced_form = producer.language_rep[producer_concept_choice][1]\n",
    "\n",
    "    distance_from_produced_form = {}\n",
    "    for concept, meaning_form in comprehender.language_rep.items():\n",
    "        # compare produced concept and all comp concepts, calculate distance between each\n",
    "        distance = sum([abs(prod_bit - comp_bit) for prod_bit, comp_bit in zip(produced_form, meaning_form[0])])\n",
    "        distance_from_produced_form[concept] = distance\n",
    "    comp_closest_meaning = min(distance_from_produced_form, key=distance_from_produced_form.get)\n",
    "\n",
    "    return comp_closest_meaning == producer_concept_choice  # returns True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a997c64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T14:51:02.313515Z",
     "start_time": "2024-10-21T14:51:02.306597Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_comprehender_concept(producer, producer_concept_choice, comprehender):\n",
    "    \"\"\" update comprehender form\n",
    "    compare all producer and comprehender form, find the ones that don't match\n",
    "    of the ones that don't match, choose one and flip this bit of the comprehender's form \"\"\"\n",
    "    comparison_list = ([(p_bit == c_bit) for p_bit, c_bit in zip(producer.language_rep[producer_concept_choice][1], comprehender.language_rep[producer_concept_choice][1])])\n",
    "    # to prevent case where correct concept has a match for form producer and comprehender\n",
    "    # this could happen if comprehender has 2 forms which both == form producer and the non-matching concept one gets chosen\n",
    "    if all(comparison_list) == True:\n",
    "        pass\n",
    "    else:\n",
    "        correctable_indexes = [i for i, comparison in enumerate(comparison_list) if comparison == False]  # get False indeces\n",
    "        chosen_index_to_correct = random.choice(correctable_indexes)\n",
    "        comprehender.language_rep[producer_concept_choice][1][chosen_index_to_correct] = abs(1 - (comprehender.language_rep[producer_concept_choice][1][chosen_index_to_correct]))\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc43833e",
   "metadata": {},
   "source": [
    "### Below is the code you need for Exercise 7b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef262f7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T14:51:03.221022Z",
     "start_time": "2024-10-21T14:51:03.215152Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_skeleton(n_concepts, n_bits):\n",
    "    \"\"\" initiate language with n_concepts and n_bits\n",
    "    in the form {0: [meaning, form], 1: [meaning, from], ...}\n",
    "    the meaning and form components are initiated with None \"\"\"\n",
    "    skeleton_concept_meaning_form = {}\n",
    "    for n in range(n_concepts):\n",
    "        skeleton_concept_meaning_form[n] = [[None] * n_bits] * 2\n",
    "    return skeleton_concept_meaning_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c791dff3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T14:51:03.626602Z",
     "start_time": "2024-10-21T14:51:03.620366Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_create_meanings(n_concepts, n_bits, n_groups):\n",
    "    \"\"\" generate the meaning representation for each group\n",
    "    returns a dictionary with group: meaning representation\n",
    "    ex. {0: [[1, 1, 0, 1, 1], [0, 0, 0, 1, 0]], 1: [[0, 0, 0, 1, 1], [1, 1, 1, 1, 0]]} \"\"\"\n",
    "    group_meaning_dic = {}\n",
    "    for n in range(n_groups):\n",
    "        condition = False\n",
    "        while condition == False:\n",
    "            single_group_meaning_list = []\n",
    "            for concept in range(n_concepts):\n",
    "                single_group_meaning_list.append(random.choices([0, 1], k=n_bits))  # list of len n_components\n",
    "            if len(set(tuple(row) for row in single_group_meaning_list)) == len(\n",
    "                    single_group_meaning_list):\n",
    "                condition = True\n",
    "                group_meaning_dic[n] = single_group_meaning_list\n",
    "                \n",
    "    return group_meaning_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e11ce3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T14:51:04.074950Z",
     "start_time": "2024-10-21T14:51:04.071164Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_add_meaning(agent, meaning_dic):\n",
    "    \"\"\" takes in the language skeleton and adds the meaning component depending on group of agent \"\"\"\n",
    "    counter = 0  # to keep track of which meaning component in meaning_dic values\n",
    "    for concept, meaning_form in agent.language_rep.items():\n",
    "        meaning_form[0] = meaning_dic[agent.group][counter]  # meaning_form[0] is the meaning only\n",
    "        counter += 1\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57e6b80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T14:51:04.458652Z",
     "start_time": "2024-10-21T14:51:04.453497Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_add_form(agent, initial_degree_of_overlap):\n",
    "    \"\"\" start with meaning representation and assign form representation\n",
    "    depending on the desired degree of overlap \"\"\"\n",
    "    for concept, meaning_form in agent.language_rep.items():\n",
    "        forms = []\n",
    "        for bit in meaning_form[0]:\n",
    "            my_choice = np.random.choice([True, False], p=[initial_degree_of_overlap, 1 - initial_degree_of_overlap])  # p = weights\n",
    "            if not my_choice:  # if my_choice == False\n",
    "                random_choice = np.random.choice([0, 1])\n",
    "                forms.append(random_choice)  # random choice 0 or 1 if False (random)\n",
    "            else:\n",
    "                forms.append(bit)  # append the same bit (iconic)\n",
    "        meaning_form[1] = forms\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4fa537",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T14:51:04.871303Z",
     "start_time": "2024-10-21T14:51:04.868030Z"
    }
   },
   "outputs": [],
   "source": [
    "class ContextAgentSimplified(Agent):\n",
    "    def __init__(self, n_concepts, n_bits, group):\n",
    "        self.group = group\n",
    "        self.language_rep = language_skeleton(n_concepts, n_bits)  # dic = {concept: [[meaning], [form]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cd183c",
   "metadata": {},
   "source": [
    "**Code to create to agents (using the ContextAgentSimplified class) from two different groups:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcee887",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T17:05:25.679643Z",
     "start_time": "2024-10-21T17:05:25.542614Z"
    }
   },
   "outputs": [],
   "source": [
    "# Code to create to agents (using the ContextAgentSimplified class) from two different groups:\n",
    "\n",
    "n_concepts = 4\n",
    "n_bits = 4\n",
    "n_groups = 2\n",
    "initial_degree_of_overlap = 0.1\n",
    "\n",
    "group_meaning_dic = language_create_meanings(n_concepts, n_bits, n_groups)\n",
    "\n",
    "agent_a_group_0 = ContextAgentSimplified(n_concepts, n_bits, 0)  # create an agent from group 0\n",
    "\n",
    "agent_b_group_0 = ContextAgentSimplified(n_concepts, n_bits, 0)  # create another agent from group 0\n",
    "\n",
    "agent_c_group_1 = ContextAgentSimplified(n_concepts, n_bits, 1)  # create an agent from group 1\n",
    "\n",
    "for agent in [agent_a_group_0 , agent_b_group_0, agent_c_group_1]:\n",
    "    language_add_meaning(agent, group_meaning_dic)  # add meaning to language skeleton\n",
    "    language_add_form(agent, initial_degree_of_overlap)  # add form to language skeleton\n",
    "\n",
    "print(\"agent_a_group_0 language_rep:\")\n",
    "print(agent_a_group_0.language_rep)\n",
    "\n",
    "print(\"agent_b_group_0 language_rep:\")\n",
    "print(agent_b_group_0.language_rep)\n",
    "\n",
    "print('')\n",
    "print(\"agent_c_group_1 language_rep:\")\n",
    "print(agent_c_group_1.language_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0942cbf1",
   "metadata": {},
   "source": [
    "**Answer to exercise 7.b):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b59865",
   "metadata": {},
   "source": [
    "#### Use the code cell below to do Exercise 7b; building on the code cells above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd5be2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6ebe604",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f078c46",
   "metadata": {},
   "source": [
    "## Exercise 8 (Model design question):\n",
    "\n",
    "This question is about agent-based cognitive modelling in general.\n",
    "\n",
    "Below is a research question, followed by a verbal explanation of what this research question is trying to get at. How would you design an agent-based model to answer this research question? (More specific instructions for what to specify follow below.)\n",
    "\n",
    "_Research question:_ What is more important for successful problem-solving: expertise or diversity?\n",
    "\n",
    "_Explanation of the question:_ Imagine a population in which individuals can develop different strategies for solving a particular problem. For ease of explanation, let's imagine the problem is something practical, and the solution is to design and build a particular tool that consists of different components. Imagine each component has a value that represents how much it contributes to solving the problem, and that an optimal solution to the problem requires a tool that combines several optimal components. Imagine individuals in this populations can have one of two possible strategies:\n",
    "\n",
    "1. Select one individual from the population who you want to learn from, spend a lot of time to perfectly acquire their solution (i.e., how to make their variant of the tool), and innovate that variant.\n",
    "2. Take in examples from many different individuals in the population, and try to combine their solutions (i.e., their variants of the tool).\n",
    "\n",
    "This research question is getting at a trade-off between accuracy of learning and diversity of input. An important assumption of your model should be that each individual has the same limited amount of time. Spending more time on learning one variant perfectly (as in strategy 1) means that you will be able to reproduce the variant more accurately, and understand better how it works (which should allow you to make more targeted innovations), but it comes at the cost of not being able to see a diverse set of solutions to the problem. Vice versa, taking in examples from different individuals in the population (strategy 2) has as an advantage that you'll be able to take in a diverse set of possible solutions to the problem (which should allow you to combine the good parts of the different solutions), but that comes at the cost of not being able to acquire/reproduce these perfectly (because you can't spend as much time learning about each individual solution).\n",
    "\n",
    "Specify, in bullet points, what the three major components of the model should consist of:\n",
    "- the agents\n",
    "- the interactions (agent-agent interactions and/or agent-environment interactions)\n",
    "- the environment\n",
    "\n",
    "If you think one of these three components is not relevant for answering this research question, write \"not relevant\" and briefly explain _why_ you believe this component is not relevant to the question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadc0b3e",
   "metadata": {},
   "source": [
    "**Answer to exercise 8):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a49a10",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05be5d2e",
   "metadata": {},
   "source": [
    "## Exercise 9 (Coding question):\n",
    "\n",
    "This question is about the Mudd et al. (2022) model.\n",
    "\n",
    "Mudd et al. (2022) find that population size has an effect on the degree of lexical variability in the population, where larger populations lead to less lexical variability (i.e., more convergence). Their explanation for this effect is that this is a result of the feedback loop illustrated in Figure 12 in the paper (copy-pasted below):\n",
    "\n",
    "\n",
    "![Fig_12](https://github.com/marieke-woensdregt/ABCM_Course_24-25/blob/main/Fig_12_feedback_loop_Mudd_et_al.png?raw=true)\n",
    "\n",
    "<img src=\"Fig_12_feedback_loop_Mudd_et_al.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "\n",
    "However, Mudd et al. (2022) do not show plots with the proportion of language game results to illustrate what this hypothesised feedback loop would look like in a single simulation. So that is what you are going to try and do below.\n",
    "\n",
    "**a)** Imagine you run a simulation contrasting a population of 5 agents with a population of 100 agents, and these simulations would behave according to the feedback loop described in Figure 12 of Mudd et al. (2022). Now imagine you would generate plots of the proportion of language game results (similar to Figures 7 and 8 from the Mudd et al. paper) for each of these populations. Describe in words what you think these plots should look like to illustrate the feedback loop. How would you expect the plots for the small and large population to be different? **Explain why**.\n",
    "\n",
    "\n",
    "**b)** Now actually run these simulations and generate the corresponding plots with the proportion of language game results, by adapting the final three code cells in this notebook (the first 15 or so code cells below load in all the code from Computer Lab 4 that you need to do run these simulations). Instead of contrasting ```n_groups``` = 1 with ```n_groups``` = 10, your code should contrast ```n_agents = 5``` with  ```n_agents = 100```.\n",
    "Set the ```n_groups``` parameter to ```n_groups = 2``` (for both simulations). \n",
    "It's worth running your simulations a couple of times to check whether the pattern you find is stable.\n",
    "Describe in a text cell whether the results in the plots you generated look like what you had predicted in part a of this exercise.\n",
    "\n",
    "**Note:** Some of the functions needed to do this run these simulations are already copy-pasted in the code cells for Exercise 7 above. If you haven't worked on Exercise 7 yet, make sure to run the code cells that belong to Exercise 7 to load in those functions before you start working on Exercise 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa2df43",
   "metadata": {},
   "source": [
    "### Necessary installations and imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42da3d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:47:06.497143Z",
     "start_time": "2024-10-16T16:47:06.493200Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "from math import sqrt\n",
    "import time\n",
    "from mesa import Agent, Model\n",
    "from mesa.datacollection import DataCollector\n",
    "from mesa.time import RandomActivation\n",
    "from mesa.batchrunner import BatchRunner, FixedBatchRunner\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a7e16",
   "metadata": {},
   "source": [
    "### Parameter settings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbd229a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:47:07.468683Z",
     "start_time": "2024-10-16T16:47:07.464557Z"
    }
   },
   "outputs": [],
   "source": [
    "################# PARAMETER SETTINGS: ################# \n",
    "\n",
    "test_params = dict(\n",
    "    n_concepts=10, # int: number of concepts\n",
    "    n_bits=10,  # int: number of bits (determining length of forms and culturally-salient feature vectors)\n",
    "    n_agents=10, # int: number of agents in the population\n",
    "    n_groups=1,  # determines how many different semantic groups there are\n",
    "    initial_degree_of_overlap=0.9,  # degree of overlap between the form and meaning components\n",
    "    n_steps=2000  # number of timesteps to run the simulation for (called \"model stages\" in the paper)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea32b0fa",
   "metadata": {},
   "source": [
    "### Initialising the population and their language representations:\n",
    "\n",
    "**Note:** These functions are already copy-pasted in the code cells for Exercise 7 above. If you haven't worked on Exercise 7 yet, make sure to run the code cells that belong to Exercise 7 to load in those functions before you start working on Exercise 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7ab483",
   "metadata": {},
   "source": [
    "### Running a language game and updating the agents' language representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4223046",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:42:43.533588Z",
     "start_time": "2024-10-16T16:42:43.529129Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_game(sorted_agent_list):\n",
    "    \"\"\" takes agent list sorted by group\n",
    "    chooses and agent to be the producer \"\"\"\n",
    "    form_success = 0\n",
    "    meaning_success = 0\n",
    "    bit_update = 0\n",
    "\n",
    "    for a in sorted_agent_list:\n",
    "        what_is_updated = language_game_structure(a, sorted_agent_list)\n",
    "\n",
    "        if what_is_updated == \"3a\":\n",
    "            form_success += 1\n",
    "        elif what_is_updated == \"3b1\":\n",
    "            meaning_success += 1\n",
    "        else:  # \"3b2\"\n",
    "            bit_update += 1\n",
    "\n",
    "    language_game_stats = {\"form_success\": form_success, \"meaning_success\": meaning_success, \"bit_update\": bit_update}\n",
    "    return language_game_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded6c997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:42:43.553756Z",
     "start_time": "2024-10-16T16:42:43.549171Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_game_structure(producer, all_agents):\n",
    "    comprehender = random.choice(all_agents)\n",
    "    producer_concept_choice = random.choice(list(producer.language_rep))  # 1\n",
    "    form_match_answer = does_closest_form_match(producer, producer_concept_choice, comprehender)  # 2\n",
    "    if form_match_answer == False:  # 3b\n",
    "        meaning_match_answer = does_closest_meaning_match(producer, producer_concept_choice, comprehender)\n",
    "        if meaning_match_answer == False:  # 3b2\n",
    "            update_comprehender_concept(producer, producer_concept_choice, comprehender)\n",
    "            return \"3b2\"\n",
    "        else:  # 3b1\n",
    "            # None\n",
    "            return \"3b1\"\n",
    "    else:  # 3a\n",
    "        # None\n",
    "        return \"3a\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20809f1",
   "metadata": {},
   "source": [
    "**Note:** The rest of the three functions for this section are already copy-pasted in the code cells for Exercise 7 above. If you haven't worked on Exercise 7 yet, make sure to run the code cells that belong to Exercise 7 to load in those functions before you start working on Exercise 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d382c",
   "metadata": {},
   "source": [
    "### Data-collector functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b1834c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:42:43.645877Z",
     "start_time": "2024-10-16T16:42:43.641169Z"
    }
   },
   "outputs": [],
   "source": [
    "# lexical variability\n",
    "def calculate_pop_lex_var(agent_list, n_concepts):\n",
    "    pairs_of_agents = itertools.combinations(agent_list, r=2)\n",
    "\n",
    "    pairs_lex_var = []\n",
    "\n",
    "    for pair in pairs_of_agents:\n",
    "        pair_lex_var = calculate_distance(pair, n_concepts)\n",
    "        pairs_lex_var.append(pair_lex_var)\n",
    "\n",
    "    pop_av_lex_var = sum(pairs_lex_var) / len(list(itertools.combinations(agent_list, r=2)))\n",
    "    return (pop_av_lex_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5662807a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:42:43.665654Z",
     "start_time": "2024-10-16T16:42:43.660986Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_distance(pair, n_concepts):\n",
    "    \"\"\" per concept per agent pair, distance = 0 if concepts are the same, distance = 1 if concepts are different\n",
    "    add up concept distances and divide by total number of concepts \"\"\"\n",
    "    concept_lex_var_total = 0  # list of distances between individual concepts (compare iconic agent a and iconic agent b)\n",
    "    for n in range(n_concepts):\n",
    "        if pair[0].language_rep[n][1] != pair[1].language_rep[n][1]:\n",
    "            concept_lex_var_total += 1  # if concepts don't match, add 1 to distance\n",
    "\n",
    "    pair_mean_lex_var = concept_lex_var_total / n_concepts\n",
    "    return pair_mean_lex_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa5e6ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:42:43.685989Z",
     "start_time": "2024-10-16T16:42:43.681000Z"
    }
   },
   "outputs": [],
   "source": [
    "# iconicity\n",
    "def calculate_degree_of_iconicity(agent):\n",
    "    concept_iconicity_vals = []\n",
    "\n",
    "    for concept, meaning_form in agent.language_rep.items():\n",
    "        comparison_list = ([(p_bit == c_bit) for p_bit, c_bit in zip(meaning_form[0], meaning_form[1])])  # returns True or False for each comparison\n",
    "        concept_iconicity_val = sum(comparison_list) / len(comparison_list)\n",
    "        concept_iconicity_vals.append(concept_iconicity_val)\n",
    "\n",
    "    mean_agent_iconicity = sum(concept_iconicity_vals) / len(concept_iconicity_vals)\n",
    "    return mean_agent_iconicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175d18b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:42:43.705024Z",
     "start_time": "2024-10-16T16:42:43.701421Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_prop_iconicity(agent_list):\n",
    "    iconicity_list = [a.prop_iconicity for a in agent_list]\n",
    "    return sum(iconicity_list) / len(agent_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38642aec",
   "metadata": {},
   "source": [
    "### Defining the agent and the model as a whole (using the Mesa package):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313701ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:42:43.727962Z",
     "start_time": "2024-10-16T16:42:43.721213Z"
    }
   },
   "outputs": [],
   "source": [
    "class ContextAgent(Agent):\n",
    "    def __init__(self, unique_id, model, n_concepts, n_bits, n_groups):\n",
    "        super().__init__(unique_id, model)\n",
    "        self.group = random.choice(range(n_groups))\n",
    "        self.language_rep = language_skeleton(n_concepts, n_bits)  # dic = {concept: [[meaning], [form]}\n",
    "        self.prop_iconicity = None\n",
    "\n",
    "    def describe(self):\n",
    "        #print(f\"id = {self.unique_id}, prop iconicity = {self.prop_iconicity}, group = {self.group}, language = {self.language_rep}\")\n",
    "        print(self.language_rep)\n",
    "\n",
    "    def step(self):\n",
    "        self.prop_iconicity = calculate_degree_of_iconicity(self)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536e5ac0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:42:43.761770Z",
     "start_time": "2024-10-16T16:42:43.745953Z"
    }
   },
   "outputs": [],
   "source": [
    "class ContextModel(Model):\n",
    "    \"\"\"A model with some number of agents.\"\"\"\n",
    "    def __init__(self, n_agents, n_concepts, n_bits, n_groups, initial_degree_of_overlap, n_steps, viz_on=False):\n",
    "        super().__init__()\n",
    "        self.placement_counter = 0\n",
    "        self.n_agents = n_agents\n",
    "        self.n_groups = n_groups\n",
    "        self.n_concepts = n_concepts\n",
    "        self.n_bits = n_bits\n",
    "        self.n_steps = n_steps\n",
    "\n",
    "        self.current_step = 0\n",
    "        self.schedule = RandomActivation(self)\n",
    "        self.running = True  # for server\n",
    "        self.group_meanings_dic = language_create_meanings(n_concepts, n_bits, n_groups) # set up language structure (maybe eventually a class)\n",
    "\n",
    "        self.width_height = int(sqrt(n_agents))\n",
    "        self.coordinate_list = list(itertools.product(range(self.width_height), range(self.width_height)))  # generate coordinates for grid\n",
    "\n",
    "        # language game successes and failures\n",
    "        self.lg_form_success = 0\n",
    "        self.lg_meaning_success = 0\n",
    "        self.lg_bit_update = 0\n",
    "        self.language_game_stats = {'form_success': None, 'meaning_success': None, 'bit_update': None}\n",
    "\n",
    "        # for datacollector\n",
    "        self.pop_iconicity = None\n",
    "        self.pop_lex_var = None\n",
    "        self.datacollector = DataCollector({'pop_iconicity': 'pop_iconicity',\n",
    "                                            'pop_lex_var': 'pop_lex_var',\n",
    "                                            'current_step': 'current_step',\n",
    "                                            'lg_form_success': 'lg_form_success',\n",
    "                                            'lg_meaning_success': 'lg_meaning_success',\n",
    "                                            'lg_bit_update': 'lg_bit_update'},\n",
    "                                           {'group': lambda agent: agent.group,\n",
    "                                            'language': lambda agent: agent.language_rep,\n",
    "                                            'prop iconicity': lambda agent: agent.prop_iconicity})\n",
    "\n",
    "        # create agents\n",
    "        for i in range(self.n_agents):\n",
    "            a = ContextAgent(i, self, self.n_concepts, self.n_bits, self.n_groups)  # make a new agent\n",
    "            language_add_meaning(a, self.group_meanings_dic)  # add meaning to language skeleton\n",
    "            language_add_form(a, initial_degree_of_overlap)  # add form to language skeleton\n",
    "\n",
    "            self.schedule.add(a)  # add agent to list of agents\n",
    "            a.prop_iconicity = calculate_degree_of_iconicity(a)\n",
    "\n",
    "        self.sorted_agents = sorted(self.schedule.agents, key=lambda agent: agent.group)  # sort agents by group\n",
    "\n",
    "    def collect_data(self):\n",
    "        self.pop_iconicity = calculate_prop_iconicity(self.schedule.agents)\n",
    "        self.pop_lex_var = calculate_pop_lex_var(self.schedule.agents, self.n_concepts)\n",
    "        self.current_step = self.current_step\n",
    "        self.lg_form_success = self.language_game_stats['form_success']\n",
    "        self.lg_meaning_success = self.language_game_stats['meaning_success']\n",
    "        self.lg_bit_update = self.language_game_stats['bit_update']\n",
    "        self.datacollector.collect(self)\n",
    "\n",
    "    def tests(self, a):\n",
    "        assert len(self.group_meanings_dic) == self.n_groups\n",
    "        assert len(self.group_meanings_dic[0]) == self.n_concepts\n",
    "        assert len(self.group_meanings_dic[0][0]) == self.n_bits\n",
    "        assert len(a.language_rep) == self.n_concepts\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\" Advance the model by one step \"\"\"\n",
    "        self.collect_data()  # set up = year 0\n",
    "\n",
    "        if self.current_step == 0:\n",
    "            self.tests(random.choice(self.schedule.agents))  # run tests on a random agent\n",
    "\n",
    "        self.current_step += 1\n",
    "        self.language_game_stats = language_game(self.sorted_agents)  # language game (only after the set up = year 0)\n",
    "\n",
    "        #if self.current_step == self.n_steps:\n",
    "        #    upgma_df = pd.DataFrame()\n",
    "\n",
    "        #    for i in self.schedule.agents:\n",
    "        #        for key, value in i.language_rep.items():\n",
    "        #            new_row = {'id': i.unique_id, 'concept': key, 'form': value[1]}\n",
    "        #            upgma_df = upgma_df.append(new_row, ignore_index=True)\n",
    "\n",
    "        #    upgma_df.to_csv(\"upgma_data.csv\")\n",
    "\n",
    "        self.schedule.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4860db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:42:48.391469Z",
     "start_time": "2024-10-16T16:42:43.779423Z"
    }
   },
   "outputs": [],
   "source": [
    "n_groups = 1\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "context_model = ContextModel(test_params[\"n_agents\"], test_params[\"n_concepts\"], test_params[\"n_bits\"], \n",
    "                             n_groups, test_params[\"initial_degree_of_overlap\"], test_params[\"n_steps\"])\n",
    "\n",
    "for i in range(test_params[\"n_steps\"]+1):  # set up = year 0 + x years\n",
    "    #print(i)\n",
    "    context_model.step()\n",
    "\n",
    "print(\"Simulation(s) took %s minutes to run\" % round(((time.time() - start_time) / 60.), 2))  # ADDED BY MW\n",
    "\n",
    "df_model_output_1_group = context_model.datacollector.get_model_vars_dataframe()\n",
    "## alternative option for the agents is get_agent_vars_dataframe(), returns ['Step', 'AgentID', 'neighborhood', 'language', 'prop iconicity']\n",
    "\n",
    "csv_save_as = \"n_concepts_\"+str(test_params[\"n_concepts\"])+\"_n_bits_\"+str(test_params[\"n_bits\"])+\"_n_agents_\"+str(test_params[\"n_agents\"])+\"_n_groups_\"+str(n_groups)+\"_overlap_\"+str(test_params[\"initial_degree_of_overlap\"])+\"_n_steps_\"+str(test_params[\"n_steps\"])\n",
    "df_model_output_1_group = pd.DataFrame(df_model_output_1_group.to_records())  # gets rid of multiindex\n",
    "df_model_output_1_group.to_csv(f\"{csv_save_as}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e900ef85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:42:53.513340Z",
     "start_time": "2024-10-16T16:42:48.431353Z"
    }
   },
   "outputs": [],
   "source": [
    "n_groups = 10\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "context_model = ContextModel(test_params[\"n_agents\"], test_params[\"n_concepts\"], test_params[\"n_bits\"], \n",
    "                             n_groups, test_params[\"initial_degree_of_overlap\"], test_params[\"n_steps\"])\n",
    "\n",
    "for i in range(test_params[\"n_steps\"]+1):  # set up = year 0 + x years\n",
    "    #print(i)\n",
    "    context_model.step()\n",
    "\n",
    "print(\"Simulation(s) took %s minutes to run\" % round(((time.time() - start_time) / 60.), 2))  # ADDED BY MW\n",
    "\n",
    "df_model_output_10_groups = context_model.datacollector.get_model_vars_dataframe()\n",
    "## alternative option for the agents is get_agent_vars_dataframe(), returns ['Step', 'AgentID', 'neighborhood', 'language', 'prop iconicity']\n",
    "\n",
    "csv_save_as = \"n_concepts_\"+str(test_params[\"n_concepts\"])+\"_n_bits_\"+str(test_params[\"n_bits\"])+\"_n_agents_\"+str(test_params[\"n_agents\"])+\"_n_groups_\"+str(n_groups)+\"_overlap_\"+str(test_params[\"initial_degree_of_overlap\"])+\"_n_steps_\"+str(test_params[\"n_steps\"])\n",
    "df_model_output_10_groups = pd.DataFrame(df_model_output_10_groups.to_records())  # gets rid of multiindex\n",
    "df_model_output_10_groups.to_csv(f\"{csv_save_as}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ae7ec3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:43:00.843687Z",
     "start_time": "2024-10-16T16:42:53.562479Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# colormap\n",
    "cmap = plt.cm.viridis\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "\n",
    "# set up 2 column figure\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, constrained_layout=True)\n",
    "fig.set_size_inches(9,3)\n",
    "\n",
    "# FIG 1 GROUP EXAMPLE RUN\n",
    "# 1 group, 10 stages on ax0\n",
    "\n",
    "# Uncomment the line below if you want to load in your dataframe from a .csv file:\n",
    "# model_output = pd.read_csv(\"\", index_col=0)\n",
    "\n",
    "model_output = df_model_output_1_group\n",
    "\n",
    "model_output = model_output[['current_step', 'lg_form_success', 'lg_meaning_success', 'lg_bit_update']]\n",
    "model_output = model_output.rename(columns={\"lg_form_success\": \"form_success\", \"lg_meaning_success\": \"culturally_salient_features_success\", \"lg_bit_update\": \"update_bit\"})\n",
    "model_output = model_output.iloc[1:11]\n",
    "model_output[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\"]] = model_output[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\"]].div(10, axis=0)\n",
    "\n",
    "# https://www.python-graph-gallery.com/13-percent-stacked-barplot\n",
    "# From raw value to percentage\n",
    "totals = [i+j+k for i, j, k in zip(model_output['update_bit'], model_output['culturally_salient_features_success'], model_output['form_success'])]\n",
    "bit_bars = [i / j for i,j in zip(model_output['update_bit'], totals)]\n",
    "features_bars = [i / j for i,j in zip(model_output['culturally_salient_features_success'], totals)]\n",
    "form_bars = [i / j for i,j in zip(model_output['form_success'], totals)]\n",
    "\n",
    "steps = range(model_output[\"current_step\"].min(), model_output[\"current_step\"].max() + 1)  # min, max steps in df\n",
    "ax0.bar(steps, bit_bars, color=cmaplist[0], width=1, edgecolor=\"none\", label=\"bit update\")  # Create green Bars\n",
    "ax0.bar(steps, features_bars, bottom=bit_bars, color=cmaplist[128], width=1, edgecolor=\"none\", label=\"CS features success\")  # Create orange Bars\n",
    "ax0.bar(steps, form_bars, bottom=[i + j for i, j in zip(bit_bars, features_bars)], color=cmaplist[-1], width=1, edgecolor=\"none\", label=\"form success\")  # Create blue Bars\n",
    "\n",
    "# axes\n",
    "ax0.set_xlabel(\"Model stage\", fontsize=15)\n",
    "ax0.set_ylim(0,1)\n",
    "ax0.set_ylabel(\"Proportion\", fontsize=15)\n",
    "ax0.set_xticks(np.arange(1, 11, 1))\n",
    "\n",
    "\n",
    "# 1 group, 2000 stages on ax1\n",
    "\n",
    "# Uncomment the line below if you want to load in your dataframe from a .csv file:\n",
    "# model_output = pd.read_csv(\"\", index_col=0)\n",
    "\n",
    "model_output = df_model_output_1_group\n",
    "\n",
    "model_output = model_output[['current_step', 'lg_form_success', 'lg_meaning_success', 'lg_bit_update']]\n",
    "model_output = model_output.rename(columns={\"lg_form_success\": \"form_success\", \"lg_meaning_success\": \"culturally_salient_features_success\", \"lg_bit_update\": \"update_bit\"})\n",
    "model_output = model_output.drop([0])\n",
    "model_output[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\"]] = model_output[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\"]].div(10, axis=0)\n",
    "\n",
    "# add column with value for groups of 50 (1-50, 51-100, etc.)\n",
    "for index, row in model_output.iterrows():\n",
    "    model_output.at[index, \"hist_block\"] = int(index/50)\n",
    "\n",
    "model_output_grouped = model_output.groupby([\"hist_block\"]).mean()\n",
    "model_output_grouped[\"original_index\"] = model_output_grouped.index * 50\n",
    "model_output = model_output_grouped[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\", \"original_index\"]]\n",
    "\n",
    "# https://www.python-graph-gallery.com/13-percent-stacked-barplot\n",
    "# From raw value to percentage\n",
    "totals = [i+j+k for i, j, k in zip(model_output['update_bit'], model_output['culturally_salient_features_success'], model_output['form_success'])]\n",
    "bit_bars = [i / j for i,j in zip(model_output['update_bit'], totals)]\n",
    "features_bars = [i / j for i,j in zip(model_output['culturally_salient_features_success'], totals)]\n",
    "form_bars = [i / j for i,j in zip(model_output['form_success'], totals)]\n",
    "\n",
    "steps = range(int(model_output.index.min()), int(model_output.index.max() + 1))  # min, max steps in df\n",
    "ax1.bar(steps, bit_bars, color=cmaplist[0], width=1, edgecolor=\"none\", label=\"bit update\")  # Create green Bars\n",
    "ax1.bar(steps, features_bars, bottom=bit_bars, color=cmaplist[128], width=1, edgecolor=\"none\", label=\"CS features success\")  # Create orange Bars\n",
    "ax1.bar(steps, form_bars, bottom=[i + j for i, j in zip(bit_bars, features_bars)], color=cmaplist[-1], width=1, edgecolor=\"none\", label=\"form success\")  # Create blue Bars\n",
    "\n",
    "# legend\n",
    "handles, labels = ax1.get_legend_handles_labels()\n",
    "handles = [handles[2], handles[1], handles[0]]\n",
    "labels = [labels[2], labels[1], labels[0]]\n",
    "ax1.legend(handles, labels, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# axes\n",
    "ax1.set_xlabel(\"Model stage\", fontsize=15)\n",
    "ax1.set_ylim(0,1)\n",
    "ax1.set_ylabel(\"\", fontsize=15)\n",
    "ax1.set_xticks(np.arange(0, 41, step=10))\n",
    "ax1.set_xticklabels([0,500,1000,1500,2000])\n",
    "\n",
    "plt.suptitle(\"1 group\", fontsize=18, x=0.4, y=1.1)\n",
    "\n",
    "plt.savefig(\"barplot_1group.png\", dpi=1000, bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "\n",
    "# FIG 10 GROUPS EXAMPLE RUN\n",
    "# set up 2 column figure\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, constrained_layout=True)\n",
    "fig.set_size_inches(9,3)\n",
    "\n",
    "# 10 groups, 10 stages on ax0\n",
    "\n",
    "# Uncomment the line below if you want to load in your dataframe from a .csv file:\n",
    "# model_output = pd.read_csv(\"\", index_col=0)\n",
    "\n",
    "model_output = df_model_output_10_groups\n",
    "\n",
    "model_output = model_output[['current_step', 'lg_form_success', 'lg_meaning_success', 'lg_bit_update']]\n",
    "model_output = model_output.rename(columns={\"lg_form_success\": \"form_success\", \"lg_meaning_success\": \"culturally_salient_features_success\", \"lg_bit_update\": \"update_bit\"})\n",
    "model_output = model_output.iloc[1:11]\n",
    "model_output[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\"]] = model_output[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\"]].div(10, axis=0)\n",
    "\n",
    "# https://www.python-graph-gallery.com/13-percent-stacked-barplot\n",
    "# From raw value to percentage\n",
    "totals = [i+j+k for i, j, k in zip(model_output['update_bit'], model_output['culturally_salient_features_success'], model_output['form_success'])]\n",
    "bit_bars = [i / j for i,j in zip(model_output['update_bit'], totals)]\n",
    "features_bars = [i / j for i,j in zip(model_output['culturally_salient_features_success'], totals)]\n",
    "form_bars = [i / j for i,j in zip(model_output['form_success'], totals)]\n",
    "\n",
    "steps = range(model_output[\"current_step\"].min(), model_output[\"current_step\"].max() + 1)  # min, max steps in df\n",
    "ax0.bar(steps, bit_bars, color=cmaplist[0], width=1, edgecolor=\"none\", label=\"bit update\")  # Create green Bars\n",
    "ax0.bar(steps, features_bars, bottom=bit_bars, color=cmaplist[128], width=1, edgecolor=\"none\", label=\"CS features success\")  # Create orange Bars\n",
    "ax0.bar(steps, form_bars, bottom=[i + j for i, j in zip(bit_bars, features_bars)], color=cmaplist[-1], width=1, edgecolor=\"none\", label=\"form success\")  # Create blue Bars\n",
    "\n",
    "# axes\n",
    "ax0.set_xlabel(\"Model stage\", fontsize=15)\n",
    "ax0.set_ylim(0,1)\n",
    "ax0.set_ylabel(\"Proportion\", fontsize=15)\n",
    "ax0.set_xticks(np.arange(1, 11, 1))\n",
    "\n",
    "# 10 groups, 2000 stages on ax1\n",
    "\n",
    "# Uncomment the line below if you want to load in your dataframe from a .csv file:\n",
    "# model_output = pd.read_csv(\"\", index_col=0)\n",
    "\n",
    "model_output = df_model_output_10_groups\n",
    "\n",
    "model_output = model_output[['current_step', 'lg_form_success', 'lg_meaning_success', 'lg_bit_update']]\n",
    "model_output = model_output.rename(columns={\"lg_form_success\": \"form_success\", \"lg_meaning_success\": \"culturally_salient_features_success\", \"lg_bit_update\": \"update_bit\"})\n",
    "model_output = model_output.drop([0])\n",
    "model_output[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\"]] = model_output[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\"]].div(10, axis=0)\n",
    "\n",
    "# add column with value for groups of 50 (1-50, 51-100, etc.)\n",
    "for index, row in model_output.iterrows():\n",
    "    model_output.at[index, \"hist_block\"] = int(index/50)\n",
    "\n",
    "model_output_grouped = model_output.groupby([\"hist_block\"]).mean()\n",
    "model_output_grouped[\"original_index\"] = model_output_grouped.index * 50\n",
    "model_output = model_output_grouped[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\", \"original_index\"]]\n",
    "\n",
    "# https://www.python-graph-gallery.com/13-percent-stacked-barplot\n",
    "# From raw value to percentage\n",
    "totals = [i+j+k for i, j, k in zip(model_output['update_bit'], model_output['culturally_salient_features_success'], model_output['form_success'])]\n",
    "bit_bars = [i / j for i,j in zip(model_output['update_bit'], totals)]\n",
    "features_bars = [i / j for i,j in zip(model_output['culturally_salient_features_success'], totals)]\n",
    "form_bars = [i / j for i,j in zip(model_output['form_success'], totals)]\n",
    "\n",
    "steps = range(int(model_output.index.min()), int(model_output.index.max() + 1))  # min, max steps in df\n",
    "ax1.bar(steps, bit_bars, color=cmaplist[0], width=1, edgecolor=\"none\", label=\"bit update\")  # Create green Bars\n",
    "ax1.bar(steps, features_bars, bottom=bit_bars, color=cmaplist[128], width=1, edgecolor=\"none\", label=\"CS features success\")  # Create orange Bars\n",
    "ax1.bar(steps, form_bars, bottom=[i + j for i, j in zip(bit_bars, features_bars)], color=cmaplist[-1], width=1, edgecolor=\"none\", label=\"form success\")  # Create blue Bars\n",
    "\n",
    "# legend\n",
    "handles, labels = ax1.get_legend_handles_labels()\n",
    "handles = [handles[2], handles[1], handles[0]]\n",
    "labels = [labels[2], labels[1], labels[0]]\n",
    "ax1.legend(handles, labels, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# axes\n",
    "ax1.set_xlabel(\"Model stage\", fontsize=15)\n",
    "ax1.set_ylim(0,1)\n",
    "ax1.set_ylabel(\"\", fontsize=15)\n",
    "ax1.set_xticks(np.arange(0, 41, step=10))\n",
    "ax1.set_xticklabels([0,500,1000,1500,2000])\n",
    "\n",
    "plt.suptitle(\"10 groups\", fontsize=18, x=0.4, y=1.1)\n",
    "\n",
    "plt.savefig(\"barplot_10groups.png\", dpi=1000, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60ec041",
   "metadata": {},
   "source": [
    "**Answer to exercise 9.a):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b6ced",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85da5afe",
   "metadata": {},
   "source": [
    "**Answer to exercise 9.b):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af04e9e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:28:44.489039Z",
     "start_time": "2024-10-16T17:28:42.215644Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52348e35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:30:35.903917Z",
     "start_time": "2024-10-16T17:28:44.611540Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd0b304",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:30:42.559141Z",
     "start_time": "2024-10-16T17:30:36.018637Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c23f464",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Cuskley, C., Loreto, V., & Kirby, S. (2018). A Social Approach to Rule Dynamics Using an Agent-Based Model. Topics in Cognitive Science, 10(4), 745758. https://doi.org/10.1111/tops.12327\n",
    "\n",
    "Mudd, K., de Vos, C., & de Boer, B. (2022). Shared Context Facilitates Lexical Variation in Sign Language Emergence. Languages, 7(1), Article 1. https://doi.org/10.3390/languages7010031\n",
    "\n",
    "Raviv, L., Meyer, A., & Lev-Ari, S. (2020). The Role of Social Network Structure in the Emergence of Linguistic Structure. Cognitive Science, 44(8), e12876. https://doi.org/10.1111/cogs.12876\n",
    "\n",
    "Waade, P. T., Enevoldsen, K. C., Vermillet, A.-Q., Simonsen, A., & Fusaroli, R. (2022). Introducing tomsup: Theory of mind simulations using Python. Behavior Research Methods. https://doi.org/10.3758/s13428-022-01827-2\n",
    "\n",
    "de Weerd, H., Verbrugge, R., & Verheij, B. (2015). Higher-order theory of mind in the Tacit Communication Game. Biologically Inspired Cognitive Architectures, 11, 1021. https://doi.org/10.1016/j.bica.2014.11.010"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
