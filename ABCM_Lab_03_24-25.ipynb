{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d66c425",
   "metadata": {},
   "source": [
    "# ABCM Computer lab 3: Population effects & Cultural evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a57939",
   "metadata": {},
   "source": [
    "This notebook contains Python code for the model by Cuskley et al. (2018), which was kindly shared with me by the first author Christine Cuskley. (Note that the simulations reported in the actual paper were run using C++ code, which is the code you can find in the GitHub repository under the link on p. 757 of the paper: https://github.com/CCuskley/RuleEmergence .)\n",
    "\n",
    "Below follows a brief walk-through of the code, with some exercises in between.\n",
    "\n",
    "To load the code into your notebook, make sure to run each of the code cells below in turn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8671afc6",
   "metadata": {},
   "source": [
    "## Activate your virtual environment\n",
    "\n",
    "If you've created a virtual environment for this course before, **don't forgot to activate your virtual environment** before running this notebook. (Activate your virtual environment from the terminal, then type ```jupyter notebook``` in the terminal to open Jupyter notebooks in the browser, then open the notebook for this computer lab, and do Kernel --> Change kernel --> ```<myenv>```, where ```<myenv>``` is the name of your virtual environment.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4174a026",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T20:53:37.361629Z",
     "start_time": "2024-09-29T20:53:37.356901Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from collections import Counter\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d97db5",
   "metadata": {},
   "source": [
    "## Parameter settings:\n",
    "\n",
    "Below are the parameter settings.\n",
    "\n",
    "Unfortunately, the code takes a while to run (hence why Cuskley et al., 2018 ended up implementing the model in C++ instead). To make it feasible to run some simulations in a reasonable amount of time, the code below therefore makes a number of changes compared to the Cuskley et al. (2018) parameter settings. See the parameter settings below; the comment after each parameter states what setting Cuskley et al. (2018) used.\n",
    "\n",
    "These measures should hopefully allow you to run the relevant simulations in ~20 minutes. \n",
    "\n",
    "Have a look at each of the parameters below, and check whether you understand which parameter or condition described in Cuskley et al. (2018) they correspond to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8fe555",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T22:39:43.083386Z",
     "start_time": "2024-09-29T22:39:43.079072Z"
    }
   },
   "outputs": [],
   "source": [
    "popSizes_to_compare = [10, 50]  # small pop size first, large pop size second. Cuskley et al. (2018) used 20 for small and 100 for large pop\n",
    "runs = 2  # number of independent simulation runs (int). Cuskley et al. (2018) used 100\n",
    "maxTime = 2000  # number of timesteps (int). Cuskley et al. (2018) used 10,000\n",
    "doReplace = True  # whether to do replacement (i.e., population turnover) or not (Boolean; True or False)\n",
    "doGrowth = False  # whether to do population growth or not (Boolean; True or False)\n",
    "\n",
    "k = 750  # token threshold for proficiency. Cuskley et al. (2018) used 1500\n",
    "d = 100  # memory window, see Cuskley et al. (2017): https://doi.org/10.1016/j.cognition.2016.11.001. Cuskley et al. used 100\n",
    "r = 0.001  # the rate of replacement for turnover. Cuskley et al. (2018) used 0.001.\n",
    "g = 0.001  # the rate of growth. Cuskley et al. (2018) used 0.001.\n",
    "lemmas = 14  # number of lemmas (int); 28 in the Cuskley et al. (2018) paper. Cuskley et al. (2018) used 28\n",
    "inflections = 6  # number of inflections (int); 12 in the Cuskley et al. (2018) paper. Cuskley et al. (2018) used 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a73b6ea",
   "metadata": {},
   "source": [
    "In the code of Cuskley et al. (2018), the ```topic_list```, which determines the frequency of each of the lemmas according to a Zipfian distribution, is hardcoded (see code cell below). However, if we want to be able to change the number of lemmas in the simulation, we need a function that generates this Zipfian distribution list with the right number of lemmas. I've written a function that does that, called ```zipfian_vocab()```, below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7df8c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T22:39:43.606523Z",
     "start_time": "2024-09-29T22:39:43.590415Z"
    }
   },
   "outputs": [],
   "source": [
    "topic_list_original_code = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 7, 7, 8, 8, 8, 8, 9, 9, 9, 10, 10, 10, 11, 11, 11, 12, 12, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
    "\n",
    "lemfreq_original_code = Counter(topic_list_original_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e453d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topic_list_original_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b87b9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(topic_list_original_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e0c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemfreq_original_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de48572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lemfreq_original_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f2d0b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T21:35:12.764963Z",
     "start_time": "2024-09-29T21:35:12.757623Z"
    }
   },
   "outputs": [],
   "source": [
    "def zipfian_vocab(n_lemmas,a, n_tokens):\n",
    "    \"\"\"\n",
    "    Generates a vocabulary (numpy array of n_tokens tokens of n_lemmas types, with Zipfian frequency distribution)\n",
    "    :param n_lemmas: int: number of lemmas\n",
    "    :param a: int: exponent (parameter a) used to create Zipfian frequency distribution. Cuskley et al., 2018 used 2\n",
    "    :param n_tokens: int: number of tokens in vocabulary. Cuskley et al. seem to have used 500 (in C++ implementation)\n",
    "    :return: (1) numpy array containing n_tokens tokens of n_lemmas types; (2) numpy array with log frequency per lemma\n",
    "    \"\"\"\n",
    "    lemma_indices = np.arange(n_lemmas)  # create numpy array with index for each lemma\n",
    "    zipf_dist = np.random.zipf(a, size=n_lemmas)  # create Zipfian frequency distribution for lemmas\n",
    "    zipf_dist_in_probs = np.divide(zipf_dist, np.sum(zipf_dist))\n",
    "    zipf_dist_for_n_tokens = np.multiply(zipf_dist_in_probs, n_tokens)\n",
    "    zipf_dist_for_n_tokens = np.ceil(zipf_dist_for_n_tokens)  # Round UP, so that we get *at least* n_tokens in vocab\n",
    "    vocabulary = np.array([])\n",
    "    for i in range(len(lemma_indices)):\n",
    "        lemma_index = lemma_indices[i]\n",
    "        lemma_freq = zipf_dist_for_n_tokens[i]\n",
    "        vocabulary = np.concatenate((vocabulary, np.array([lemma_index for x in range(int(lemma_freq))])))\n",
    "    for j in range(2):  # doing this twice because sth weird w/ np.delete() function: doesn't always delete all indices\n",
    "        # (possibly to do with later index going out of bounds once previous indices have been deleted)\n",
    "        if vocabulary.shape[0] > n_tokens:  # if vocab is larger than n_tokens, randomly remove excess tokens\n",
    "            random_indices = np.random.choice(np.arange(vocabulary.shape[0]), size=(vocabulary.shape[0] - n_tokens))\n",
    "            vocabulary = np.delete(vocabulary, random_indices)\n",
    "    vocabulary = vocabulary.astype(int)\n",
    "    return vocabulary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ba0cb4",
   "metadata": {},
   "source": [
    "### Always re-run the code cell below after changing the lemmas parameter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285bce75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T21:35:14.658009Z",
     "start_time": "2024-09-29T21:35:14.654075Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2 is what Cuskley et al. (2018) used as the exponent (parameter a) for the Zipfian distribution, and 500 is the\n",
    "# length of the topic_list from the original code:\n",
    "\n",
    "topic_list = zipfian_vocab(lemmas, 2, 500)\n",
    "\n",
    "lemfreq = Counter(topic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d553ab99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T21:35:15.506919Z",
     "start_time": "2024-09-29T21:35:15.502352Z"
    }
   },
   "outputs": [],
   "source": [
    "topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaec55d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T21:35:16.281754Z",
     "start_time": "2024-09-29T21:35:16.278673Z"
    }
   },
   "outputs": [],
   "source": [
    "len(topic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f5ee9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T21:35:17.213990Z",
     "start_time": "2024-09-29T21:35:17.210724Z"
    }
   },
   "outputs": [],
   "source": [
    "lemfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebcd376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T21:35:18.560677Z",
     "start_time": "2024-09-29T21:35:18.557738Z"
    }
   },
   "outputs": [],
   "source": [
    "len(lemfreq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160b75f1",
   "metadata": {},
   "source": [
    "## The Agent class:\n",
    "\n",
    "Below is the definition of the ```Agent``` class. The main attribute that an ```Agent``` object consists of is its matrix ```self.matrix```. This matrix represents the agent's vocabulary. For each possible lemma-inflection pairing, the matrix contains 4 entries (which are all initialised at 0). By running the code cell below, you can see what an empty version of an agent's matrix looks like (i.e., before the agent has done any interactions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db592f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(shape=(lemmas,inflections), dtype = (float, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c518d49",
   "metadata": {},
   "source": [
    "As is explained in the comment in the ```Agent.__init__()``` method, these 4 entries represent: ```[successes, total inters., weight (successes/total inters), last heard]```. \n",
    "\n",
    "That is: \n",
    "\n",
    "- ```self.matrix[L][I][0]``` keeps track of the number of communicative successes achieved with that particular lemma-inflection pairing.\n",
    "- ```self.matrix[L][I][1]``` keeps track of the total number of interactions in which the agent has used that particular lemma-inflection pairing.\n",
    "- ```self.matrix[L][I][2]``` keeps track of the _relative_ successfullness of that particular lemma-inflection pairing: i.e., the number of times it led to communicative success, divided by the total number of times it was used.\n",
    "- ```self.matrix[L][I][3]``` keeps track of at which timestep this lemma-inflection pairing was last heard (this is relevant for the ```Agent.purgeLemmas()``` method which implements the memory decay that Cuskley et al., 2018 describe on page 750).\n",
    "\n",
    "Have a look at the ```.updateInflection()``` method of the ```Agent``` class to see how these four entries inside the agent's vocabulary matrix are updated.\n",
    "\n",
    "Then have a look at where/when the ```.updateInflection()``` method is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab16acf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T21:35:56.637055Z",
     "start_time": "2024-09-29T21:35:56.617791Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class Agent:\n",
    "    def __init__(self,L,I):\n",
    "        self.tokens=0\n",
    "        self.typeGen=False\n",
    "        self.isActive=False\n",
    "        self.matrix = np.zeros(shape=(L,I), dtype = (float, 4))\n",
    "        #the above generates L=28 Lemmas\n",
    "        #the index is the identity of the lemma.\n",
    "        #each Lemma has a list of 12 inflection arrays\n",
    "        #the index of each inflection is its identity\n",
    "        #each inflection array has 4 zeros initially,\n",
    "        #standing in for:\n",
    "        #[successes, total inters., weight (successes/total inters), last heard]\n",
    "\n",
    "    \n",
    "    def resetAgent(self, L,I):\n",
    "        self.isActive=True\n",
    "        self.tokens=0\n",
    "        self.typeGeneralise=False\n",
    "        self.matrix = np.zeros(shape=(L,I), dtype = (float, 4)) \n",
    "\n",
    "    def resetLemma(self,L):\n",
    "        for infl in self.matrix[L]:\n",
    "            self.matrix[L][infl]=[0,0,0,0]\n",
    "\n",
    "    def updateInflection(self, L,I, outcome, tstep):\n",
    "        self.matrix[L][I][0]+=outcome\n",
    "        self.matrix[L][I][1]+=1\n",
    "        self.matrix[L][I][2]=self.matrix[L][I][0]/self.matrix[L][I][1]\n",
    "        self.matrix[L][I][3]=tstep\n",
    "        if self.typeGeneralise==False:\n",
    "            self.tokens+=1\n",
    "            if self.tokens>k:\n",
    "                typeGeneralise=True\n",
    "\n",
    "    def hasInflections(self,L):\n",
    "        hasInts=False\n",
    "        for i in range(inflections):\n",
    "            if self.matrix[L][i][2]>0:\n",
    "                hasInts=True\n",
    "                break\n",
    "        return hasInts\n",
    "\n",
    "    def getBestInfl(self, L):        \n",
    "        bestWeight= -0.5\n",
    "        bestInfl=0\n",
    "        for i in range(inflections):\n",
    "            if self.matrix[L][i][2]>bestWeight:\n",
    "                bestWeight=self.matrix[L][i][2]\n",
    "                bestInfl=i\n",
    "        if bestWeight<=0:\n",
    "            return -1\n",
    "        else:\n",
    "            return bestInfl\n",
    "\n",
    "    def purgeLemmas(self, tstep):\n",
    "        for l in range(lemmas):\n",
    "            for i in range(inflections):\n",
    "                if tstep-self.matrix[l][i][3]>d:\n",
    "                    self.matrix[l][i]=[0,0,0,0]\n",
    "\n",
    "    def typeGeneralise(self):\n",
    "#         maxTypes=[0,0,0,0,0,0,0,0,0,0,0,0]  # This was hard-coded in the original code\n",
    "        maxTypes = [0 for x in range(inflections)]\n",
    "        for l in range(lemmas):\n",
    "            bestinfl=self.getBestInfl(l)\n",
    "            if bestinfl>=0:\n",
    "                maxTypes[bestinfl]+=1\n",
    "        maxval=max(maxTypes)\n",
    "        if maxval==0:\n",
    "            #we dont have any best inflections, choose randomly.\n",
    "#             return random.randint(0,11)  # This was hard-coded in the original code\n",
    "            return random.randint(0,inflections-1)\n",
    "        else:\n",
    "            #break ties\n",
    "            ties=[]\n",
    "            for m in range(len(maxTypes)):\n",
    "                if maxTypes[m]==maxval:\n",
    "                    ties.append(m)\n",
    "            return random.choice(ties)\n",
    "\n",
    "\n",
    "    def tokenGeneralise(self):        \n",
    "#         maxTokens=[0,0,0,0,0,0,0,0,0,0,0,0]  # This was hard-coded in the original code\n",
    "        maxTokens = [0 for x in range(inflections)]\n",
    "        for l in range(lemmas):\n",
    "            for i in range(inflections):\n",
    "                maxTokens[i]+=self.matrix[l][i][0]\n",
    "        maxval=max(maxTokens)\n",
    "        if maxval==0:\n",
    "            #we dont have any best inflections, choose randomly.\n",
    "#             return random.randint(0,11)  # This was hard-coded in the original code\n",
    "            return random.randint(0,inflections-1)\n",
    "        ties=[]\n",
    "        for m in range(len(maxTokens)):\n",
    "            if maxTokens[m]==maxval:\n",
    "                ties.append(m)\n",
    "        return random.choice(ties)\n",
    "\n",
    "    def genInfl(self,L):\n",
    "        hasInfl=self.hasInflections(L)\n",
    "        if hasInfl:\n",
    "            bestinfl=self.getBestInfl(L)\n",
    "            if bestinfl>=0:\n",
    "                return bestinfl\n",
    "            else:\n",
    "                hasInfl=False\n",
    "        if hasInfl==False:            \n",
    "            if(self.typeGen):\n",
    "                return self.typeGeneralise()\n",
    "            else:\n",
    "                return self.tokenGeneralise()\n",
    "\n",
    "    def hear(self,L,infl,tstep):\n",
    "        if self.matrix[L][infl][1]>0:\n",
    "            outcome=1\n",
    "        else:\n",
    "            guess=self.genInfl(L)\n",
    "            if guess==infl:\n",
    "                outcome=1\n",
    "            else:\n",
    "                outcome=0\n",
    "        self.updateInflection(L,infl,outcome,tstep)\n",
    "        return outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc7b5ec",
   "metadata": {},
   "source": [
    "**Exercise 1:**\n",
    "\n",
    "**a)** What do the L and the I in the ```Agent.__init__()``` method stand for? (Inspect the code in order to figure this out.) And what variables in the list of parameter settings above would be the right variables to give as input arguments for L and I when initialising an Agent object?\n",
    "\n",
    "**b)** In a code cell below, create two Agent objects, and save them in variables called ```agent_a``` and ```agent_b```, respectively. Then print and inspect the vocabulary matrices of each of these two agents (see the ```__init__()``` method of the ```Agent``` class)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bb230c",
   "metadata": {},
   "source": [
    "**Answer to exercise 1.a):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b57f7ab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "510b48ae",
   "metadata": {},
   "source": [
    "**Answer to exercise 1.b):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e089a41e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba0a02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9c9df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ebee05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3affd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4eb1473",
   "metadata": {},
   "source": [
    "**Exercise 2:**\n",
    "\n",
    "**a)** In a code cell below, write some code to have your ```agent_a``` and ```agent_b``` interact with each other for 28 rounds (i.e., twice the number of lemmas). Your code should have the following features:\n",
    "- ```agent_a``` and ```agent_b``` should take turns being the speaker and the hearer.\n",
    "- At each interaction, a random lemma should be selected as the 'topic' for the agents to talk about.\n",
    "- After the speaker agent has produced an utterance, and the hearer agent has interpreted that utterance, both agents should update their vocabulary matrices accordingly.\n",
    "\n",
    "In order to write this code, use the following three methods from the ```Agent``` class:\n",
    "\n",
    "- ```Agent.genInfl()```\n",
    "- ```Agent.hear()```\n",
    "- ```Agent.updateInflection()```\n",
    "\n",
    "**Tip 1:** Before you start writing your code, have a look at how these three methods are defined in the ```Agent``` class above.\n",
    "\n",
    "**Tip 2:** Before you start writing your code, have a look at how these three methods are used in the ```doRuns()``` function below (under the heading _Running simulations_).\n",
    "\n",
    "**Tip 3:** Inspect the ```Agent.hear()``` method carefully, to find out what is needed in order to have the two different agents update their vocabulary matrix.\n",
    "\n",
    "**b)** After having ```agent_a``` and ```agent_b``` interact with each other for 28 timesteps, inspect how their vocabularies have changed, by printing their vocabulary matrices again. Is there a lemma-inflection pair with which ```agent_b``` has had 100% communicative success so far? And what does the entry for that lemma-inflection pair look like for ```agent_a```, compared to for ```agent_b```?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ce70cc",
   "metadata": {},
   "source": [
    "**Answer to exercise 2.a):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f37f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b99cd880",
   "metadata": {},
   "source": [
    "**Answer to exercise 2.b):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4363b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2e0c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f1a2202",
   "metadata": {},
   "source": [
    "## Measuring regularity and stability:\n",
    "\n",
    "The functions below are used to measure the regularity and the stability of the language system in the population (see section 2.1.4. _Measuring the system_ in the Cuskley et al., 2018 paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9d2faf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T21:35:57.276281Z",
     "start_time": "2024-09-29T21:35:57.271153Z"
    }
   },
   "outputs": [],
   "source": [
    "def measureRegularity(p):\n",
    "#     inflcts=[0,0,0,0,0,0,0,0,0,0,0,0]  # This was hard-coded in the original code\n",
    "    inflcts = [0 for x in range(inflections)]\n",
    "    for i in range(inflections):\n",
    "        for agnt in p:\n",
    "            for lem in range(lemmas):\n",
    "                if agnt.genInfl(lem)==i:\n",
    "                    inflcts[i]+=1\n",
    "    inflprobs=[]\n",
    "    activeCt=0\n",
    "    for ct in inflcts:\n",
    "        inflprobs.append(ct / len(p) * lemmas)\n",
    "        if ct>0:\n",
    "            activeCt+=1\n",
    "    return {\"Hv\":entropy(inflprobs),\"activeCount\":activeCt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8138b933",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T21:35:57.918936Z",
     "start_time": "2024-09-29T21:35:57.914637Z"
    }
   },
   "outputs": [],
   "source": [
    "def measureStability(p, L):\n",
    "#     inflcts=[0,0,0,0,0,0,0,0,0,0,0,0]  # This was hard-coded in the original code\n",
    "    inflcts = [0 for x in range(inflections)]\n",
    "    for i in range(inflections):\n",
    "        for agnt in p:\n",
    "            if agnt.genInfl(L)==i:\n",
    "                inflcts[i]+=1\n",
    "    inflprobs=[]\n",
    "    for ct in inflcts:\n",
    "        inflprobs.append(ct/len(p))\n",
    "    return entropy(inflprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f3c1f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T21:35:58.603614Z",
     "start_time": "2024-09-29T21:35:58.598021Z"
    }
   },
   "outputs": [],
   "source": [
    "def getRegIndex(p):\n",
    "#     inflcts=[0,0,0,0,0,0,0,0,0,0,0,0]  # This was hard-coded in the original code\n",
    "    inflcts = [0 for x in range(inflections)]\n",
    "    for i in range(inflections):\n",
    "        for agnt in p:\n",
    "            for lem in range(lemmas):\n",
    "                if agnt.genInfl(lem)==i:\n",
    "                    inflcts[i]+=1\n",
    "    inflvals=list(set(inflcts))\n",
    "    inflvals.sort()\n",
    "    ranks=[]\n",
    "    for i in range(inflections):\n",
    "        ranks.append(inflvals.index(inflcts[i]))\n",
    "    return ranks.index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e7de36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T21:35:59.252673Z",
     "start_time": "2024-09-29T21:35:59.249580Z"
    }
   },
   "outputs": [],
   "source": [
    "def probReg(L,topInfl,p):\n",
    "    tops=0\n",
    "    for agnt in p:\n",
    "        if agnt.genInfl(L)==topInfl:\n",
    "            tops+=1\n",
    "    return tops/len(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7338c3c6",
   "metadata": {},
   "source": [
    "## Running simulations:\n",
    "\n",
    "The ```doRuns()``` function below runs several runs of a given simulation, and saves the results of the ```measureRegularity``` function and the ```measureStability()``` function in two dictionaries (in a format that makes it easy to convert into a ```Pandas``` dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fea0d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T21:35:59.876144Z",
     "start_time": "2024-09-29T21:35:59.863128Z"
    }
   },
   "outputs": [],
   "source": [
    "def doRuns(popSize, regularity_dictionary, stability_dictionary):\n",
    "    for run in range(runs):\n",
    "        pop=[]\n",
    "        interTime=0\n",
    "        for a in range(popSize):\n",
    "            pop.append(Agent(lemmas, inflections))\n",
    "        print(\"New population of \", popSize,\" starting agents initialised.\")\n",
    "        print(\"Starting run number \", run,  \"for \",maxTime,\" timesteps, where one step is \",popSize,\" interactions...\")\n",
    "        for t in range(maxTime):\n",
    "            #memory check at the start of a timestep\n",
    "            if t>d:\n",
    "                for p in pop:\n",
    "                    p.purgeLemmas(t)\n",
    "            #now get to interacting\n",
    "            for i in range(popSize):\n",
    "                s=random.randint(0,len(pop)-1)\n",
    "                h=random.randint(0,len(pop)-1)\n",
    "                while s==h:\n",
    "                    h=random.randint(0,len(pop)-1)\n",
    "                topic=random.choice(topic_list)\n",
    "                if pop[s].hasInflections(topic):\n",
    "                    utterance=pop[s].getBestInfl(topic)\n",
    "                else:\n",
    "                    utterance=pop[s].genInfl(topic)\n",
    "                result=pop[h].hear(topic,utterance,t)#hearing entails update, returns result\n",
    "                pop[s].updateInflection(topic,utterance,result,t)\n",
    "\n",
    "                #REPLACEMENT AND GROWTH HERE\n",
    "                if doReplace:\n",
    "                    rDice=random.uniform(0,1)\n",
    "                    if rDice<=r:\n",
    "                        #make a random agent a baby\n",
    "                        youbaby=random.randint(0,len(pop)-1)\n",
    "                        pop[youbaby].resetAgent(lemmas, inflections)\n",
    "                if doGrowth:\n",
    "                    gDice=random.uniform(0,1)\n",
    "                    if gDice<=g:\n",
    "                        #add an agent\n",
    "                        pop.append(Agent(lemmas, inflections))\n",
    "                        \n",
    "            #Recording each timestep: number of active inflections and hv\n",
    "            regInfo=measureRegularity(pop)\n",
    "            regularity_dictionary[\"Run\"].append(run)\n",
    "            regularity_dictionary[\"Timestep\"].append(t)\n",
    "            regularity_dictionary[\"InitPopSize\"].append(popSize)\n",
    "            regularity_dictionary[\"H_v\"].append(regInfo[\"Hv\"])\n",
    "            regularity_dictionary[\"ActiveInfl\"].append(regInfo[\"activeCount\"])\n",
    "\n",
    "        reg = getRegIndex(pop)\n",
    "        for l in range(lemmas):\n",
    "            stability_dictionary[\"Run\"].append(run)\n",
    "            stability_dictionary[\"InitPopSize\"].append(popSize)\n",
    "            stability_dictionary[\"EndPopSize\"].append(len(pop))\n",
    "            stability_dictionary[\"LemmaIndex\"].append(l)\n",
    "            stability_dictionary[\"LemmaFrequency\"].append(lemfreq[l]/len(topic_list))\n",
    "            stability_dictionary[\"H_l\"].append(measureStability(pop,l))\n",
    "            stability_dictionary[\"PropReg\"].append(probReg(l,reg,pop))\n",
    "\n",
    "    return regularity_dictionary, stability_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d620e29",
   "metadata": {},
   "source": [
    "The code cell below defines a function called ```run_simulations()``` that can run a number of simulations (as many as specified by the ```runs``` parameter), for each population size as specified by the ```popSizes_to_compare``` parameter. The ```run_simulations()``` function calls the ```doRuns()``` function defined above.\n",
    "\n",
    "The ```run_simulations()``` function returns to output variables: ```regularity_dataframes_combined``` and ```stability_dataframes_combined```. These are two ```pandas``` dataframes, which contain the results of the ```measureRegularity``` function and the ```measureStability()``` function, respectively.\n",
    "Before returning this output, the ```run_simulations()``` function also saves those pandas dataframes as ```pickle``` files on your machine, so you don't lose your simulation results if you close this notebook. (It saves the files to the same folder that this notebook is in.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac80bf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T22:30:35.327029Z",
     "start_time": "2024-09-29T21:36:00.704855Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_simulations():\n",
    "    regularity_results_per_popSize = []\n",
    "    stability_results_per_popSize = []\n",
    "    for i in range(len(popSizes_to_compare)):\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        popSize = popSizes_to_compare[i]\n",
    "\n",
    "        print(\"Prepping for N=\",popSize,\"; replace=\",doReplace,\"; grow=\",doGrowth,\". Doing \", runs,\" runs, each for \",maxTime,\"timesteps.\")\n",
    "\n",
    "        regularity_dictionary = {\"Run\":[], \"Timestep\":[], \"InitPopSize\":[], \"H_v\":[], \"ActiveInfl\":[]}\n",
    "        stability_dictionary = {\"Run\":[], \"InitPopSize\":[], \"EndPopSize\":[], \"LemmaIndex\":[], \"LemmaFrequency\":[], \"H_l\":[], \"PropReg\":[]}\n",
    "\n",
    "        regularity_results, stability_results = doRuns(popSize, regularity_dictionary, stability_dictionary)\n",
    "\n",
    "        regularity_dataframe = pd.DataFrame(regularity_results)\n",
    "\n",
    "        stability_dataframe = pd.DataFrame(stability_results)\n",
    "\n",
    "        regularity_results_per_popSize.append(regularity_dataframe)\n",
    "\n",
    "        stability_results_per_popSize.append(stability_dataframe)\n",
    "\n",
    "        end = time.time()\n",
    "        print(\"Run time for popSize \"+str(popSize)+\" in min.:\")\n",
    "        print((end - start) / 60.)\n",
    "\n",
    "\n",
    "    regularity_dataframes_combined = pd.concat(regularity_results_per_popSize)\n",
    "\n",
    "    stability_dataframes_combined = pd.concat(stability_results_per_popSize)\n",
    "\n",
    "    #  Let's make sure we save the resulting dataframes (as a pickle file), so that we can reuse them later, without\n",
    "    #  having to run the whole simulation again. And let's put all the parameter settings in the file name, so that\n",
    "    #  new simulation files with slightly different parameter settings cannot accidentally overwrite earlier ones\n",
    "    #  (this creates very long filenames, but it's worth it, to be on the save side):\n",
    "\n",
    "    regularity_dataframes_combined.to_pickle(\"./regularity_dataframes_combined_\"+\"small_pop_\"+str(popSizes_to_compare[0])+\"_large_pop_\"+str(popSizes_to_compare[1])+\"_runs_\" + str(runs) + \"_tsteps_\" + str(maxTime) + \"_replacement_\" + str(doReplace) + \"_growth_\" + str(doGrowth) + \"_n_lem_\" + str(lemmas) + \"_n_infl_\" + str(\n",
    "            inflections) + \"_k_\" + str(k) +\".pkl\")\n",
    "\n",
    "    stability_dataframes_combined.to_pickle(\"./stability_dataframes_combined_\"+\"small_pop_\"+str(popSizes_to_compare[0])+\"_large_pop_\"+str(popSizes_to_compare[1])+\"_runs_\" + str(runs) + \"_tsteps_\" + str(maxTime) + \"_replacement_\" + str(doReplace) + \"_growth_\" + str(doGrowth) + \"_n_lem_\" + str(lemmas) + \"_n_infl_\" + str(\n",
    "            inflections) + \"_k_\" + str(k) +\".pkl\")\n",
    "\n",
    "    return regularity_dataframes_combined, stability_dataframes_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f58b7f",
   "metadata": {},
   "source": [
    "The code cell below calls the run_simulation() function to run simulations with the parameter settings that were specified at the top of the notebook. Using those parameter settings, running the code cell below should take about 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d608fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "regularity_dataframes_combined, stability_dataframes_combined = run_simulations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013b6811",
   "metadata": {},
   "source": [
    "## Inspecting the dataframes with simulation results:\n",
    "\n",
    "Let's inspect the dataframes that were created, for the different population sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac30b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T22:40:25.099105Z",
     "start_time": "2024-09-29T22:40:25.084011Z"
    }
   },
   "outputs": [],
   "source": [
    "regularity_dataframes_combined[regularity_dataframes_combined[\"InitPopSize\"]==popSizes_to_compare[0]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2f5b6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T22:40:25.800050Z",
     "start_time": "2024-09-29T22:40:25.791247Z"
    }
   },
   "outputs": [],
   "source": [
    "regularity_dataframes_combined[regularity_dataframes_combined[\"InitPopSize\"]==popSizes_to_compare[0]].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3caedb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T22:40:27.789787Z",
     "start_time": "2024-09-29T22:40:27.781715Z"
    }
   },
   "outputs": [],
   "source": [
    "regularity_dataframes_combined[regularity_dataframes_combined[\"InitPopSize\"]==popSizes_to_compare[1]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b77c9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T22:40:28.301796Z",
     "start_time": "2024-09-29T22:40:28.293581Z"
    }
   },
   "outputs": [],
   "source": [
    "regularity_dataframes_combined[regularity_dataframes_combined[\"InitPopSize\"]==popSizes_to_compare[1]].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe18be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "regularity_dataframes_combined[\"InitPopSize\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aa6978",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T22:40:30.593755Z",
     "start_time": "2024-09-29T22:40:30.584647Z"
    }
   },
   "outputs": [],
   "source": [
    "stability_dataframes_combined[stability_dataframes_combined[\"InitPopSize\"]==popSizes_to_compare[0]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f399cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_dataframes_combined[stability_dataframes_combined[\"InitPopSize\"]==popSizes_to_compare[0]].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fb4ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_dataframes_combined[stability_dataframes_combined[\"InitPopSize\"]==popSizes_to_compare[1]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d70bd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T22:40:31.432005Z",
     "start_time": "2024-09-29T22:40:31.422982Z"
    }
   },
   "outputs": [],
   "source": [
    "stability_dataframes_combined[stability_dataframes_combined[\"InitPopSize\"]==popSizes_to_compare[1]].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3677e6b",
   "metadata": {},
   "source": [
    "Run the code cell below to check whether there are at least some fluctuations/variations in the stability of the lexicon over time in your simulations. If the code cell below returns 0.0, you might need to increase the population sizes a little bit, or the number of timesteps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33dce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(stability_dataframes_combined[\"H_l\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11616d4",
   "metadata": {},
   "source": [
    "## Plotting the simulation results:\n",
    "\n",
    "The code cell below defines three plotting functions that reproduce plots (A), (B) and (C) from Figures 2 and 3 of the Cuskley et al. (2018) paper. \n",
    "The plotting functions also save your plots as pdf files on your machine (again in the same folder as where you have this notebook saved).\n",
    "\n",
    "**Note** that the ```plot_lemma_entropy_by_freq()``` function, hich reproduces subplot (B), doesn't show the x-axis on a log-scale. This is because in our simulations, we're working with smaller populations, so the values for the lemma frequency don't get as large as in the Cuskley et al. (2018) paper. If you _do_ want to see what it looks like with the x-axis on a log scale, simply uncomment the line that says ```plt.xscale('log')``` in the definition of the ```plot_lemma_entropy_by_freq()``` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f069a33f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T22:41:42.392824Z",
     "start_time": "2024-09-29T22:41:42.380745Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_vocab_entropy(regularity_df, plot_title):\n",
    "    plt.figure()\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.displot(data=regularity_df, x=\"H_v\", hue=\"InitPopSize\", kind=\"kde\", fill=True, palette=sns.color_palette(\"colorblind\", 2))\n",
    "    plt.title(plot_title) # Set figure title\n",
    "    plt.savefig(\"./Hv_plot_\" + \"small_pop_\"+str(popSizes_to_compare[0])+\"_large_pop_\"+str(popSizes_to_compare[1])+\"_runs_\" + str(runs) + \"_tsteps_\" + str(maxTime) + \"_replacement_\" + str(doReplace) + \"_growth_\" + str(doGrowth) + \"_n_lem_\" + str(lemmas) + \"_n_infl_\" + str(\n",
    "        inflections) + \"_k_\" + str(k) + \".pdf\")\n",
    "\n",
    "\n",
    "def plot_lemma_entropy_by_freq(stability_df, plot_title):\n",
    "    plt.figure()\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.lineplot(data=stability_df, x=\"LemmaFrequency\", y=\"H_l\", hue=\"InitPopSize\", palette=sns.color_palette(\"colorblind\", 2))\n",
    "#     plt.xscale('log') #  Uncomment this line if you want to display the x-axis on a log scale, like in the paper\n",
    "    plt.title(plot_title) # Set figure title\n",
    "    plt.savefig(\"./Hl_plot_\"+ \"small_pop_\"+str(popSizes_to_compare[0])+\"_large_pop_\"+str(popSizes_to_compare[1])+\"_runs_\"+str(runs)+\"_tsteps_\" + str(maxTime) +\"_replacement_\"+str(doReplace)+\"_growth_\"+str(doGrowth)+\"_n_lem_\"+str(lemmas)+\"_n_infl_\"+str(inflections)+\"_k_\"+str(k)+\".pdf\")\n",
    "\n",
    "\n",
    "def plot_active_inflections_over_time(regularity_df, plot_title):\n",
    "    plt.figure()\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.lineplot(data=regularity_df, x=\"Timestep\", y=\"ActiveInfl\", hue=\"InitPopSize\", palette=sns.color_palette(\"colorblind\", 2))\n",
    "    plt.title(plot_title) # Set figure title\n",
    "    plt.savefig(\"./Inflections_plot_\"+\"small_pop_\"+str(popSizes_to_compare[0])+\"_large_pop_\"+str(popSizes_to_compare[1])+\"_runs_\"+str(runs)+\"_tsteps_\" + str(maxTime) +\"_replacement_\"+str(doReplace)+\"_growth_\"+str(doGrowth)+\"_n_lem_\"+str(lemmas)+\"_n_infl_\"+str(inflections)+\"_k_\"+str(k)+\".pdf\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce955a58",
   "metadata": {},
   "source": [
    "The code cells below show you how to call these three plotting functions. The second input argument is the title of the plot, you can change this accordingly when you change your parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022e1420",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T22:41:43.842475Z",
     "start_time": "2024-09-29T22:41:43.462300Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plot_vocab_entropy(regularity_dataframes_combined, \"Turnover: Distribution end-state Hv values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fefa7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T06:35:06.777834Z",
     "start_time": "2024-08-30T06:35:06.547603Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plot_lemma_entropy_by_freq(stability_dataframes_combined, \"Turnover: Mean end-state Hl by lemma frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1744c115",
   "metadata": {},
   "source": [
    "Just FYI: Running the ```plot_active_inflections_over_time()``` function below takes a bit more time than the other two plotting functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c1bf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T06:35:09.623071Z",
     "start_time": "2024-08-30T06:35:09.404097Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plot_active_inflections_over_time(regularity_dataframes_combined, \"Turnover: Active inflections over time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e6d2c4",
   "metadata": {},
   "source": [
    "**Exercise 3:**\n",
    "\n",
    "**a)** Run a simulation that is similar to the _Turnover_ condition from the Cuskley et al. (2018) paper (section 3.1. _Turnover_; pp. 752-754, and Figure 2), but with smaller populations and fewer lemmas and inflections in the system. Start by using the following parameter settings:\n",
    "\n",
    "- ```popSizes_to_compare = [10, 50]``` (half of what they used in Cuskley et al., 2018)\n",
    "- ```runs = 5``` (1/20th of what they used in Cuskley et al., 2018)\n",
    "- ```maxTime = 2000``` (1/5th of what they used in Cuskley et al., 2018)\n",
    "- ```k = 750``` (half of what they used in Cuskley et al., 2018)\n",
    "- ```d = 100``` (same as in Cuskley et al., 2018)\n",
    "- ```r = 0.001``` (same as in Cuskley et al., 2018)\n",
    "- ```g = 0.001``` (same as in Cuskley et al., 2018)\n",
    "- ```lemmas = 14``` (half of what they used in Cuskley et al., 2018)\n",
    "- ```inflections = 6``` (half of what they used in Cuskley et al., 2018)\n",
    "\n",
    "How should you set the ```doReplace``` and the ```doGrowth``` parameters in order to reproduce the _Turnover_ condition from Cuskley et al. (2018)?\n",
    "\n",
    "I've copy-pasted the code cell with the parameter settings below, to make it easy for you to change them without having to scroll all the way back up to the top of the notebook.\n",
    "\n",
    "\n",
    "**b)** Make plots of your simulation results that are similar to plots (A), (B) and (C) from Figure 2 of the Cuskley et al. (2018) paper. Compare your plots to the corresponding subplots of Figure 2 in the Cuskley et al. (2018) paper, and describe how the results look similar or different. If the pattern of results looks qualitately different for a given subplot, try to explain what could be causing this (i.e., what is different in your simulations compared to those of Cuskley et al., 2018)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fde94ae",
   "metadata": {},
   "source": [
    "**Answer to exercise 3.a):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c520b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "popSizes_to_compare = [10, 50]  # small pop size first, large pop size second. Cuskley et al. (2018) used 20 for small and 100 for large pop\n",
    "runs = 2  # number of independent simulation runs (int). Cuskley et al. (2018) used 100\n",
    "maxTime = 2000  # number of timesteps (int). Cuskley et al. (2018) used 10,000\n",
    "doReplace = True  # whether to do replacement (i.e., population turnover) or not (Boolean; True or False)\n",
    "doGrowth = False  # whether to do population growth or not (Boolean; True or False)\n",
    "\n",
    "k = 750  # token threshold for proficiency. Cuskley et al. (2018) used 1500\n",
    "d = 100  # memory window, see Cuskley et al. (2017): https://doi.org/10.1016/j.cognition.2016.11.001. Cuskley et al. used 100\n",
    "r = 0.001  # the rate of replacement for turnover. Cuskley et al. (2018) used 0.001.\n",
    "g = 0.001  # the rate of growth. Cuskley et al. (2018) used 0.001.\n",
    "lemmas = 14  # number of lemmas (int); 28 in the Cuskley et al. (2018) paper. Cuskley et al. (2018) used 28\n",
    "inflections = 6  # number of inflections (int); 12 in the Cuskley et al. (2018) paper. Cuskley et al. (2018) used 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f42d143",
   "metadata": {},
   "source": [
    "**If you've made a change to the number of lemmas:** Don't forget to also regenerate the topic_list, by simply re-running the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310dd452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 is what Cuskley et al. (2018) used as the exponent (parameter a) for the Zipfian distribution, and 500 is the\n",
    "# length of the topic_list from the original code:\n",
    "\n",
    "topic_list = zipfian_vocab(lemmas, 2, 500)\n",
    "\n",
    "lemfreq = Counter(topic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def4f0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcbbfb09",
   "metadata": {},
   "source": [
    "**Answer to exercise 3.b):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608e4148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64bbff75",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0502f08d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8eeb24e8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03a4aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc3a26c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a62ce03d",
   "metadata": {},
   "source": [
    "**Exercise 4:**\n",
    "\n",
    "**a)** Run a simulation that is similar to the _Growth_ condition from the Cuskley et al. (2018) paper (section 3.2. _Growth_; pp. 754-755, and Figure 3), but with smaller populations and fewer lemmas and inflections in the system. Start by using the following parameter settings (same as for Exercise 3a):\n",
    "\n",
    "- ```popSizes_to_compare = [10, 50]``` (half of what they used in Cuskley et al., 2018)\n",
    "- ```runs = 5``` (1/20th of what they used in Cuskley et al., 2018)\n",
    "- ```maxTime = 2000``` (1/5th of what they used in Cuskley et al., 2018)\n",
    "- ```k = 750``` (half of what they used in Cuskley et al., 2018)\n",
    "- ```d = 100``` (same as in Cuskley et al., 2018)\n",
    "- ```r = 0.001``` (same as in Cuskley et al., 2018)\n",
    "- ```g = 0.001``` (same as in Cuskley et al., 2018)\n",
    "- ```lemmas = 14``` (half of what they used in Cuskley et al., 2018)\n",
    "- ```inflections = 6``` (half of what they used in Cuskley et al., 2018)\n",
    "\n",
    "How should you set the ```doReplace``` and the ```doGrowth``` parameters in order to reproduce the _Growth_ condition from Cuskley et al. (2018)?\n",
    "\n",
    "\n",
    "**b)** Make plots of your simulation results that are similar to plots (A), (B) and (C) from Figure 3 of the Cuskley et al. (2018) paper. Compare your plots to the corresponding subplots of Figure 3 in the Cuskley et al. (2018) paper, and describe how the results look similar or different. If the pattern of results looks qualitately different for a given subplot, try to explain what could be causing this (i.e., what is different in your simulations compared to those of Cuskley et al., 2018)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff1338b",
   "metadata": {},
   "source": [
    "**Answer to exercise 4.a):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55c05dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "popSizes_to_compare = [10, 50]  # small pop size first, large pop size second. Cuskley et al. (2018) used 20 for small and 100 for large pop\n",
    "runs = 2  # number of independent simulation runs (int). Cuskley et al. (2018) used 100\n",
    "maxTime = 2000  # number of timesteps (int). Cuskley et al. (2018) used 10,000\n",
    "doReplace = True  # whether to do replacement (i.e., population turnover) or not (Boolean; True or False)\n",
    "doGrowth = False  # whether to do population growth or not (Boolean; True or False)\n",
    "\n",
    "k = 750  # token threshold for proficiency. Cuskley et al. (2018) used 1500\n",
    "d = 100  # memory window, see Cuskley et al. (2017): https://doi.org/10.1016/j.cognition.2016.11.001. Cuskley et al. used 100\n",
    "r = 0.001  # the rate of replacement for turnover. Cuskley et al. (2018) used 0.001.\n",
    "g = 0.001  # the rate of growth. Cuskley et al. (2018) used 0.001.\n",
    "lemmas = 14  # number of lemmas (int); 28 in the Cuskley et al. (2018) paper. Cuskley et al. (2018) used 28\n",
    "inflections = 6  # number of inflections (int); 12 in the Cuskley et al. (2018) paper. Cuskley et al. (2018) used 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee994d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e927cd5e",
   "metadata": {},
   "source": [
    "**Answer to exercise 4.b):**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3a0212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ce3db97",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c196ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bc25c61",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fb75f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "555afb64",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9729e3a4",
   "metadata": {},
   "source": [
    "**BONUS Exercise 5:** \n",
    "\n",
    "Have a look at the Cuskley et al. (2018) paper: In the growth condition, was there also population turnover (i.e., replacement)? Or did all agents from the initial population stay in the population?\n",
    "\n",
    "Also describe where in the paper you found the answer to this question, and how you infer your answer from what it says in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc102ef",
   "metadata": {},
   "source": [
    "**Answer to BONUS exercise 5:**\n",
    "\n",
    "[Your answer should start here, and, depending on the question, may consist of one or more text cells and/or code cells. You can create as many text and/or code cells as you need in order to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57d0719",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8fde8e2",
   "metadata": {},
   "source": [
    "If you're working in a virtual environment, **don't forget to deactivate your virtual environment** using the ```deactivate``` command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f677f4",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Cuskley, C., Loreto, V., & Kirby, S. (2018). A Social Approach to Rule Dynamics Using an Agent-Based Model. Topics in Cognitive Science, 10(4), 745758. https://doi.org/10.1111/tops.12327"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abcm",
   "language": "python",
   "name": "abcm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
